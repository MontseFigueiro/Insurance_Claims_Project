---
title: "Regresión con GBM"
author: "Montse Figueiro & Aniana González"
date: "27 de octubre de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##REGRESIÓN CON GBM (Gradient Boosted Machine)

###Librerias
```{r}
library(caret)
library(gbm)
memory.limit(90000)
```

###Carga de Datos

Utilizamos las mismas 5000 observaciones que habíamos utilizado en SVM para poder hacer la comparativa de los modelos.

```{r}
sample_train <- read.csv("sample_train_5000.csv")
sample_train_down <- read.csv("sample_train_down.csv")
test <- read.csv("testdf.csv")
```

###Fichero Test para Validación

```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1", "Var2", "Var3", "Var4", "Var5", "Var6","Var7", "Var8", "NVCat", "NVVar1", "NVVar2", "NVVar3", "NVVar4")
test_gbm <- test[,cols]
test_gbm_output <- test[,"Claim_Amount"]
```


##GBM REGRESIÓN CON DATOS DESEQUILIBRADOS

Método desarrollado para la clasificación para reducir el sesgo que se añaden a los modelos para aprender los errores de clasificación de los modelos existentes. Se ha generalizado y adaptado en forma de Gradient Boosted Machine (GBM) para su uso con los árboles de decisión de clasificación y regresión.


###SIN LOG TRANSFORMACIÓN

```{r}
model_gbm1 <- gbm(Claim_Amount~., data=sample_train,distribution="gaussian",n.trees = 1000)
prediction1 <- predict(model_gbm1,test_gbm,n.trees=1000)
sqrt(mean((test_gbm_output-prediction1)^2))
```
RSME = 48.13307


###CON LOG TRANSFORMACIÓN

```{r}
model_gbm2 <- gbm(log(Claim_Amount+1)~., data=sample_train,distribution="gaussian",n.trees = 1000)
prediction2 <- predict(model_gbm2,test_gbm,n.trees=1000)
sqrt(mean((test_gbm_output-prediction2)^2))
```
RSME = 39.35099

##K-FOLD CROSS-VALIDATION CON CARET 

Si lo ejecutamos con method= "svmLinear" los resultados son los mismos que ejecutando CVM con el paquete "e1071". 

###Sin LOG transformación
```{r}
ctrl <- trainControl(method="repeatedcv",repeats=5,number = 10)
model_caret_gbm <- train(Claim_Amount~.,data=sample_train, method = "gbm", trControl = ctrl)
model_caret_gbm
```

|interaction.depth | n.trees|  RMSE   |   Rsquared  |
|----|-----|-----|-----|
|  1      |             50   |   106.9766|  0.02863827|
|  1       |           100  |    106.9344|  0.03001587|
|  1        |          150  |    106.9473|  0.03037122|
|  2         |          50  |    107.4892|  0.03026116|
|  2          |        100  |    108.2174|  0.02772537|
|  2           |       150  |    108.6716|  0.02799684|
|  3            |       50  |    107.8446|  0.03016242|
|  3             |     100  |    108.8614|  0.02762303|
|  3              |    150  |    109.5989|  0.02681473|

```{r}
prediction_caret <- predict(model_caret_gbm,test_gbm)
sqrt(mean((test_gbm_output-prediction_caret)^2))
```
RSME= 57.31009

###Con LOG transformación

```{r}
ctrl <- trainControl(method="repeatedcv",repeats=5,number = 10)
model_caret_gbm_log <- train(log(Claim_Amount+1)~.,data=sample_train, method = "gbm", trControl = ctrl)
model_caret_gbm_log
```
 
|interaction.depth|  n.trees | RMSE   |   Rsquared |
|----|-----|-----|-----|
| 1          |         50    |  1.196356|  0.1123940|
|  1           |       100    |  1.181745 | 0.1295291|
|  1            |      150    |  1.174935 | 0.1371299|
|  2             |      50    |  1.169607 | 0.1506846|
|  2              |    100    |  1.156314 | 0.1644910|
|  2               |   150    |  1.151622 | 0.1686907|
|  3            |   50      |1.154309 | 0.1701062|
|  3             |     100   |   1.144279 | 0.1794945|
|  3              |    150    |  1.143413  |0.1786540|



```{r}
prediction_caret_log <- predict(model_caret_gbm_log,test_gbm)
sqrt(mean((test_gbm_output-prediction_caret_log)^2))
```
39.34993

##REGRESION SVR CON DATOS EQUILIBRADOS

Vamos a partir del fichero downSample como para el resto de nuestros modelos para ajustar el modelo y comprobar con la predicción sobre el fichero test cual es el RMSE.

###SIN LOG TRANSFORMACIÓN

```{r}
model_gbm3 <- gbm(Claim_Amount~., data=sample_train_down,distribution="gaussian",n.trees = 1000)
summary(model_gbm3)
prediction3 <- predict(model_gbm3,test_gbm,n.trees=1000)
sqrt(mean((test_gbm_output-prediction3)^2))
```
RSME = 122.6814


###CON LOG TRANSFORMACIÓN

```{r}
model_gbm4 <- gbm(log(Claim_Amount+1)~., data=sample_train_down,distribution="gaussian",n.trees = 1000)
summary(model_gbm4)
prediction4 <- predict(model_gbm4,test_gbm,n.trees=1000)
sqrt(mean((test_gbm_output-prediction4)^2))
```
RSME = 39.35612


##K-FOLD CROSS-VALIDATION CON CARET PARA "Least Squares Support Vector Machine" en Datos Equilibrados

###Sin LOG transformación
```{r}
ctrl <- trainControl(method="repeatedcv",repeats=5,number = 10)
model_caret_gbm2 <- train(Claim_Amount~.,data=sample_train_down, method = "gbm", trControl = ctrl)
model_caret_gbm2
min(model_caret_gbm2$results["RMSE"])
```

| interaction.depth | n.trees|  RMSE  |    Rsquared  |
|----|-----|-----|-----|
|  1      |             50|      281.1104 | 0.05305882|
|  1       |           100 |     280.3729 | 0.05555733|
|  1        |          150  |    280.2858 | 0.05559467|
| 2         |          50   |   281.0628 | 0.05045275|
|  2          |        100    |  281.4255 | 0.04848147|
| 2           |       150     | 282.2355 | 0.04516142|
|  3            |       50      |281.7959 | 0.04595110|
| 3             |     100      |283.0363 | 0.04228916|
|  3              |    150      |284.7311 | 0.03805902|


```{r}
prediction_caret2 <- predict(model_caret_gbm2,test_gbm)
sqrt(mean((test_gbm_output-prediction_caret2)^2))
```
151.0573

###Con LOG transformación

```{r}
ctrl <- trainControl(method="repeatedcv",repeats=5,number = 10)
model_caret_gbm_log2 <- train(log(Claim_Amount+1)~.,data=sample_train_down, method = "gbm", trControl = ctrl)
model_caret_gbm_log2
min(model_caret_gbm_log2$results["RMSE"])
```

|interaction.depth|  n.trees|  RMSE    |  Rsquared |
|-----|-----|------|------|
|  1              |     50  |    2.026460|  0.2636104|
|  1              |    100  |    1.9613061|  0.2904541|
|  1              |    150  |    1.929692 | 0.3075081|
|  2              |     50  |    1.947264 | 0.3041004|
|  2              |    100  |    1.884237 | 0.3397761|
|  2              |    150  |    1.856169 | 0.3554072|
|  3              |     50  |    1.900072 | 0.3342330|
|  3              |    100  |    1.845919 | 0.3632660|
|  3              |    150  |    1.826670 | 0.3732873|


```{r}
prediction_caret_log2 <- predict(model_caret_gbm_log2,test_gbm)
sqrt(mean((test_gbm_output-prediction_caret_log2)^2))
```
39.38117

##Seleccionamos modelo con menor RSME

Prediction con log transformación y sin equilibrado de datos.

```{r}
test$predGBM <- prediction_caret_log
write.csv(test,"testdf.csv",row.names = FALSE)
```