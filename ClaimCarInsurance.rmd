---
title: "Claim Car Insurance"
author: "Montse Figueiro & Aniana González"
date: "6 de julio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##
The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer's vehicle.


* Cada Fila contiene la información anual sobre el seguro de un vehículo.  
* La variable "Claim_Amount" ha sido ajustada para tener en cuenta los efectos de las características no correspondientes al vehículo, pero pueden tener interacciones interesantes con las variables del vehículo.
* "Calendar_Year" es el año en el que el vehículo fué asegurado.
* "Household_ID" es la identificación del hogar, en un hogar puede haber más de un vehículo asegurado.
* "Vehicle" es el número que identifica al vehículo, pero el mismo vehículo no tiene porque tener el mismo número en los diferentes años.
* Tenemos para identifiar el vehículo Model_Year, Blind_Make (manufacturer), Blind_Model, Blind_Submodel.
* El resto de columnas contienen características del vehículo así como, otras características asociadas a la poliza.
* Las variables numéricas han sido normalizadas, tienen media 0 y desviación standar 1.
* Tenemos dos datasets:
    + Training de 2005-2007 para construir el modelo
    + Test de 2008-2009 sobre el que realizaremos las predicciones.

##Objetivo del Estudio

* Problema de Clasificación

Determinar que vehículos asegurados tendrán siniestros con daño corporal en los años 2008-2009, para ello utilizaremos el training dataset que nos aporta la información correspondiente a los años 2005-2006-2007, el cual volveremos a dividir en dos partes Training y Test data set para poder contrastar los resultados de la clasificación. Por último aplicaremos el modelo al Test dataset para 2008-2009.

    + K-vecinos (necesario normalizar)
    + Arboles de decisión (no necesario normalizar)
    + Bayes (Aprendizaje Probabilistico)
    + Random Forest
    + Validación: ROC, 

* Problema de Regresión

El objetivo del estudio es conseguir predecir en función de las características del vehículo los pagos por daño corporal ocasionados anualmente por cada vehículo.

    + Random Forest Regresión.
    + Previsión Datos numéricos - Métodos de Regresión
        + GLM
        + LM (PCA)
        + SVM
        + GBM
    + Neutral Networks
    
* Validación: Caret, ROC (visualización), Cross-validation, jackknife

Tipicamente en Seguros aplicamos los siguientes métodos:

Decision Trees, Random Forests, Gradient Boosting Machines, Neural Networks and Support Vector Machines

##Code Book Variables

[Dictionary](https://kaggle2.blob.core.windows.net/competitions-data/kaggle/2509/dictionary.html?sv=2012-02-12&se=2016-09-11T09%3A28%3A10Z&sr=b&sp=r&sig=LDorwQLrH%2BUJeduG58UByqlaxlatNMpte4iJZLhM0V8%3D)




##Lectura de Datos
```{}
library(data.table)
train <- fread("train_set.csv")
test <- read.csv("test_set.csv")
str(train)
summary(train)
```

###problema de memoria

```{r}
memory.limit()
memory.limit(size=45960)
```

###Cambiamos los tipos de variables:

Las categóricas pasan a Factor: 
```{r}
class(train)
train <- as.data.frame(train)
```

```{r}
library(plyr)
train[6:20] <- lapply(train[6:20], as.factor) 
train$NVCat <- as.factor(train$NVCat)
train$OrdCat <- as.factor(train$OrdCat)
```



Tenemos el año de la póliza y el año del vehículo, hemos comprobado que ninguna de las variables numérica se corresponde con la antigûedad del coche pero podemos calcularla y puede ser un dato muy interesante:

```{r}
train$EdadVehiculo <- as.numeric(train$Calendar_Year-train$Model_Year)
```
¿normalizamos la edadvehiculo?

Tenemos valores negativos en la edad del vehículo, es decir que si el año de la póliza es 2005 el año del modelo es 2006:
Tenemos 155.991 coches con edades negativas,las vamos a dejar a 0 porque no tiene lógica 

```{r}
train$EdadVehiculo <- ifelse(train$EdadVehiculo<0,0,train$EdadVehiculo)
```
```{r}
train[train=="?"] <- NA
```

##Problemas que nos encontramos en nuestra base de datos:

* Número elevado de Missing Values
* Multicolinealidad 
* Datos desproporcionados. 99% Claim_Amount = 0.
    * Under-Sampling: Eliminamos observaciones = 0, solo vale para ahorrar tiempo, perdemos información.
    * Over-Sampling: Implica hacer copias de la Clase mínima causando overfitting.
    * Este no suele ser un problema para la regressión logística.
    * Métodos de penalización como Ridge o Lasso funcionan bien en regressiones binomial.
    * logit and probit aproximan el 0 al mismo ratio que el 1.


ESQUEMA A REALIZAR:

Train >>> casos_completos >>> Sample_casos_completos >>> Eliminar ID >>> Partición Train/Test >>> Oversampling >>> "Data Frame compensado" >>> Eliminar Variables


##Problema con "Imbalanced Training Data", más del 99% de los datos están clasificados como 0.

Tanto en el fichero Train como en el de Casos_Completos el 99% de los datos está clasificado como 0 con lo que cualquie predicción que hagamos nos va a dar 0.

En éste caso al tener más de 13 millones de observaciones podriamos realizar un under-sampling, que consiste en disminuir el número de observaciones con Claim_Amount=0.


```{r}    
casos_completos <- train[complete.cases(train),]
casos_completos$classification <- ifelse(casos_completos$Claim_Amount==0,"0","1")
casos_completos$classification <- as.factor(casos_completos$classification)
casos_completos <- casos_completos[,4:37]
casos_completos$Calendar_Year <- NULL
casos_completos$Blind_Make <- NULL
casos_completos$Blind_Model <- NULL
casos_completos$Blind_Submodel <- NULL

##sample_casos_completos <- casos_completos[sample(nrow(casos_completos), 60000), ]
sample_casos_completos <- casos_completos
prop.table(table(sample_casos_completos$classification))
```    

CARET, partimos la base de datos en dos:
```{r}
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(sample_casos_completos$classification, p = .50,list = FALSE,times = 1)
train_sample <- sample_casos_completos[ splitIndex,]
prop.table(table(train_sample$classification))
test_sample <- sample_casos_completos[-splitIndex,]
test_sample_clas <- test_sample$classification
test_sample$classification <- NULL
```
SMOTE, over-resampling.

```{r}
install.packages("DMwR")
library(DMwR)
dput(names(train_sample))
train_SMOTE <- SMOTE(classification~.,train_sample,perc.over = 100,perc.under = 200)
table(train_SMOTE$classification)
table(train_sample$classification)
head(train_SMOTE)
```
ROSE para hacer el resampling de la base de datos, ,por defecto utiliza el método Both, una mezcla de Over and Under. El problema de ROSE son los datos que genera.
```{r}
library(ROSE)
train_ROSE <- ROSE(classification ~ ., data = train_sample, seed = 1)$data
table(train_ROSE$classification)
table(train_sample$classification)

```               
El train_sample tenía 20000 observaciones con 151 positivas. ROSE nos deja la base de datos con 10000 observaciones, las reduce pero nos amplia a 10000 las positivas.


##Multicolinearidad de las variables, eliminación variables.

A partir de nuestra nueva base de datos creada con Rose y ya equilibrada, seleccionamos las variables que no tienen colinealidad:

CRAMER's V
```{r}
cv.test = function(x,y) {
  CV = sqrt(chisq.test(x, y, correct=FALSE)$statistic /
    (length(x) * (min(length(unique(x)),length(unique(y))) - 1)))
  print.noquote("Cramér V / Phi:")
  return(as.numeric(CV))
}

#Cramer V
with(train_SMOTE, cv.test(Cat2, Cat8))
```

correlationmatrix <- cor(train_SMOTE[,15:22])
correlationmatrix
highlyCorrelated <- findCorrelation(correlationmatrix, cutoff=0.5)
highlyCorrelated



```{r}
modelok73complete <- casos_completos[casos_completos$Blind_Submodel=="K.7.3",]
#Tenemos 164865 observaciones del vehiculo K.7.3 que estan completas.
require(plyr)
df1 <- ddply(casos_completos, c("Blind_Submodel","Cat1","Cat4","Cat5","Cat6","Cat7"), summarize, total=sum(Claim_Amount))
```

Categoricas:

```{r}
summary(train_SMOTE)
chisq.test(train_SMOTE$Cat4,train_SMOTE$Cat10)

#Interpretación Chi-test:
#Para las variables Cat10,Cat11 y Cat12 0.71,0.321 y 0.1287 no podemos rechazar la hipotesis nula de que las variables son independientes. Para el resto de las variables p-value es 0.

library(polycor)

pruebahetcor <- train_SMOTE[,c("Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")]
#Interpretación 
corrhetcor <- hetcor(pruebahetcor)
corrhetcor$correlations


oneway.test(casos_completos$Claim_Amount~casos_completos$Var1, var.equal = TRUE)
```
VIF variables numéricas:
```{r}
model <- lm(Var1~Var5+Var3+Var4+Var2+Var6+Var7+Var8,train_SMOTE)
summary(model)
Rsq = summary(model)$r.squared
Rsq
1/(1-Rsq)
```




Podemos prescindir de las variables "Blind_Make" y "Blind_Model" porque están incluidas dentro de "Blind_Submodel", hemos comprobado que Blind_Submodel incluye esas variables:
```{r}
pruebasubmodel <- train[train$Blind_Submodel=="K.2.4",]
summary(pruebasubmodel)
```

Pruebas desglose Submodel:
----------------
train$largo <- nchar(levels(train$Blind_Make)[train$Blind_Make])
train$largo_model <- nchar(levels(train$Blind_Model)[train$Blind_Model])
train$largo_submodel <- nchar(levels(train$Blind_Submodel)[train$Blind_Submodel])
train$make <- ifelse(train$largo_submodel==5,substr(train$Blind_Submodel,1,3),ifelse(train$largo_submodel==6,substr(train$Blind_Submodel,1,4),ifelse(train$largo_submodel==7,substr(train$Blind_Submodel,1,5),ifelse(train$largo_submodel==8,substr(train$Blind_Submodel,1,6),"NA"))))
train$make <- as.factor(train$make)
str(train$Blind_Model)
str(train$make)
----------------------

##Visualización e imputación de NA's
```{r}
library(VIM)
library(mice)
```

##Tratamiento Missing values

Han sido borrados del Test dataset pero no del training dataset. Están como "?". 
¿¿Tenemos casillas en blanco???
Hay 4 variables con más de 4 millones de NA's

Sustituimos los "?" por NA:
```{r}
train[train=="?"] <- NA
```

Tabla resumen Missing Values por Variable:
```{r}
Tabla_NAs <- as.data.frame(sapply(train, function(x) sum(is.na(x))))
colnames(Tabla_NAs) <- c("NumNAs")
Tabla_NAs$Porcentaje <- round((Tabla_NAs$NumNAs/nrow(train))*100,2)
Tabla_NAs
sum(Tabla_NAs$NumNAs)
```
Tenemos en total 23.438.318 de Missing Values, en el campo Porcentaje se indica el tanto por ciento de NA's sobre el total de observaciones de esa variables.

Seleccionamos de la tabla solo las variables que tienen NAs:

```{r}
TablaNas_Positive <- Tabla_NAs[Tabla_NAs$NumNAs>0,]
TablaNas_Positive
```

Tabla con Valores más frecuentes para cada Variable Categórica:
```{r}
values <- sapply(train,function(x) max(table(x)))
values <- as.data.frame(values)
nombres <- sapply(train,function(x) names(which.max(table(x))))
nombresvar <- as.data.frame(nombres)
clasevar <- sapply(train,function(x) class(x))
clasevar <- as.data.frame(clasevar)
Tabla_var_frecuentes <- as.data.frame(rownames(nombresvar))
Tabla_var_frecuentes$Tipo <- nombresvar$nombres
Tabla_var_frecuentes$Observaciones <- values$values
Tabla_var_frecuentes$Clasevar <- clasevar$clasevar
colnames(Tabla_var_frecuentes) <- c("Variable","Tipomasfrecuente","Observaciones","Clase_variable")
Tabla_var_frecuentes <- Tabla_var_frecuentes[Tabla_var_frecuentes$Clase_variable=="factor",]
Tabla_var_frecuentes$Porcentaje <- round((Tabla_var_frecuentes$Observaciones/nrow(train))*100,2)
Tabla_var_frecuentes
```

Agregado de Blind_Submodel, número de observaciones para cada submodelo:
```{r}
submodelos <- as.data.frame(train$Blind_Submodel)
submodelos$count <- as.numeric(1)
agregado_submodelos <- aggregate(count~`train$Blind_Submodel`,submodelos,sum)
#Añadimos una fila con los NA que la función aggregate excluye
modelos_NA <- count(is.na(train$Blind_Submodel))
newrow <- c("NA",8431)
agregado_submodelos <- rbind(agregado_submodelos,newrow)
agregado_submodelos$count <- as.numeric(agregado_submodelos$count)
head(agregado_submodelos[order(-agregado_submodelos[,2]), ])
```
Hay 8431 observaciones con 48 siniestros con daño corporal a los que les falta Blind_Make, Blind_Model y Blind_Submodel:

```{r}
obs_without_model <- train[is.na(train$Blind_Submodel),]
dim(obs_without_model)
```

Contamos los casos completos (no tienen ningún NA) y los casos incompletos (tienen algún NA)
```{r}
sum(complete.cases(train)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(train)) # Count of incomplete cases
```

Sumamos cuantos NA tiene cada observación:
```{r}
NAS <- as.data.frame(rowSums(is.na(train)))
NAS$`rowSums(is.na(train))` <- as.factor(NAS$`rowSums(is.na(train))`)
summary(NAS)
```
3706301 casos no tienen NA y 3114961 tienen 1 NA.

--------------------------------------------------------------------

```{r}
casoscon1NA <- train[train$NAS==1,]
Tabla1NAs <- as.data.frame(sapply(casoscon1NA, function(x) sum(is.na(x))))
colnames(Tabla1NAs) <- "1NA"
#Tenemos 2255420 en Cat2 y 849145 en Cat7
Tabla1NAs
```
```{r}
casoscon2NA <- train[train$NAS==2,]
Tabla2NAs <- as.data.frame(sapply(casoscon2NA, function(x) sum(is.na(x))))
colnames(Tabla2NAs) <- "2NA"
Tabla1NAs$`2NA` <- Tabla2NAs$`2NA`
```
```{r}
casoscon3NA <- train[train$NAS==3,]
Tabla3NAs <- as.data.frame(sapply(casoscon3NA, function(x) sum(is.na(x))))
colnames(Tabla3NAs) <- "3NA"
Tabla1NAs$`3NA` <- Tabla3NAs$`3NA`
```
```{r}
casoscon4NA <- train[train$NAS==4,]
Tabla4NAs <- as.data.frame(sapply(casoscon4NA, function(x) sum(is.na(x))))
colnames(Tabla4NAs) <- "4NA"
Tabla1NAs$`4NA` <- Tabla4NAs$`4NA`
Tabla1NAs
```
----------------------------------------------------------
##Visualización con VIM de las variables con NA:

```{r}
cols <- rownames(TablaNas_Positive)
cols_with_NA <- train[,cols]
head(cols_with_NA)
```
```{r}
jpeg("Missing_Pattern.jpeg")
train_aggr = aggr(cols_with_NA, numbers=TRUE, sortVars=TRUE, labels=names(cols_with_NA), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
dev.off()
```

Como hemos comprobado en nuestra tabla "TablaNAs_Positive" solamente las variables categóricas tienen Missing Values:

|Variable|Número de NA|Porcentaje|
|--------|------------|----------|
|Blind_Make|        8431  |     0.06|
|Blind_Model|       8431  |     0.06|
|Blind_Submodel|    8431  |     0.06|
|Cat1           |  25981  |     0.20|
|Cat2   |        4874164  |    36.97|
|Cat3    |          3999  |     0.03|
|Cat4     |      5631649  |    42.71|
|Cat5      |     5637321  |    42.76|
|Cat6     |        25981  |     0.20|
|Cat7     |      7167634  |    54.36|
|Cat8      |        3364  |     0.03|
|Cat10      |       3917  |     0.03|
|Cat11       |     31469  |     0.24|
|OrdCat       |     7546  |     0.06|


Vemos que hay relación entre la variable Blind_Submodel y las categóricas, siendo Cat1,Cat4,Cat5,Cat6,Cat7 iguales cuando se trata del mismo modelo de vehículo.

k.7.3
```{r}
modelok73 <- train[train$Blind_Submodel=="K.7.3",]
cols <- c("Blind_Submodel","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")
modelok73 <- modelok73[,cols]
uniquemodelok73 <-lapply(modelok73,unique)
uniquemodelok73
```




##Encontrar patrones de los Missing Values con "mice"

Tenemos 8431 observaciones que tienen missing values en las variables "Blind_Make","Blind_Model" y "Blind_Submodel", para estas variables el número de niveles es muy elevado. Como máximo las variables pueden tener 50 categorías diferentes. Vamos a realizar 3 operaciones para conseguir implementar los missing values:
Lo primero que vamos a hacer es separar train en dos data.frame vamos a quitar los 8451 observaciones el las que Submodel es NA porque al tener más de 2000 niveles nos da problemas a la hora de predecir el resto de las variables ya que Mice solo nos permite 50.
```{r}
train_1 <-  train[!is.na(train$Blind_Submodel),]
train_2 <- train[is.na(train$Blind_Submodel),]
dim(train_1)
dim(train_2)
```

seleccionamos solo las columnas con Missing Values para encontrar patrones, todas las variables son categóricas (Factor).

```{r}
train_Missing_Values <- train_1[,8:21]
unique(is.na(train_Missing_Values$Blind_Submodel))#no hay ningún NA en el submodel
train_Missing_Values_muestra <- train_Missing_Values[1:10000,]
patron_muestra <- md.pattern(train_Missing_Values_muestra)
```

##Imputación de los Missing Value con MICE

Con el data.frame que creamos con anterioridad ya podemos realizar la imputación de los missing Value con "mice":

```{r}
imp <- mice(data=train_Missing_Values_muestra, m=2,method= "polyreg", seed = 1234,MaxNWts = 2000)
```
El paquete mice tarda en exceso, así que probamos otro de los paquetes de R "Amelia"

install.packages("Amelia")
library(Amelia)
imp.amelia <- amelia(train_Missing_Values_muestra, noms=colnames(train_Missing_Values_muestra))
Vemos que 317 coches tienen los datos completos desde Cat1 a Cat9.


Añadir columna clasificación:
```{r}
train$classification <- ifelse(train$Claim_Amount==0,"0","1")
train$classification <- as.factor(train$classification)
```
##Comprobación de datos normalizados en variables numéricas (nosotros no hemos realizado la normalización pero tenemos que conocer que ha sido hecha):

```{r}
var_col <- c("Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVVar1","NVVar2","NVVar3","NVVar4")
var_num <- train[,var_col]
round(sapply(var_num,function(x) mean(x)),0)
round(sapply(var_num,function(x) sd(x)),0)
```
##Visualización de Datos


Número de Pólizas por año
```{r}
count <- table(train$Calendar_Year)
df <- data.frame(group=names(count),count)
df$percent <-round((df$Freq/sum(df$Freq))*100,2)
df <- df[-1]
df
```
Pie Chart:
```{r}
slices <- df$Freq 
lbls <-df$Var1
pct <- df$percent
lbls <- paste("Año ",lbls, sep="")
lbls <- paste(lbls, pct,sep=": ") # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pct,labels = lbls, col=rainbow(length(lbls)),
  	main="Desglose Pólizas con Siniestro por Año")
```

Gráfico Variables categóricas - distribución tipo de variable:
```{r}
library(scales) 
gr2.a <- ggplot(train, aes(Cat1)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gr2.a + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()
```


summary(train$Row_ID)


Las 4 últimas variables no son variables del vehículo, con lo que se corresponden con variables de la póliza, podemos analizar en que casos la póliza ha tenido cobertura para daño corporal.
```{r}
claim_poliza <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza[order(-claim_poliza$Claim_Amount),])
dim(claim_poliza)
claim_poliza_amount <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = sum)
head(claim_poliza_amount[order(-claim_poliza_amount$Claim_Amount),])
claim_poliza_class <- aggregate(Claim_Amount ~ classification + NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza_class[order(-claim_poliza_class$Claim_Amount),])

```


##Caso A:

```{r}
train[is.na(train$Blind_Make)] <- "?"
train[is.na(train$Blind_Model)] <- "?"
train[is.na(train$Blind_Submodel)] <- "?"

cols <- c("Calendar_Year","Model_Year","Blind_Make","Blind_Model","Blind_Submodel","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVCat","NVVar1","NVVar2","NVVar3","NVVar","Claim_Amount")
train_mice_A <- train[,4:35]
muestra_A <- train_mice_A[1:100000,]
imp <- mice(muestra_A, m=10,method= "polyreg", seed = 1234)


```

##Eliminamos Vehículos Duplicados
Para ello quitamos las variables Id (Row_ID,Vehicle,Calendar_Year). Dejamos Household_ID para tener algún identificador de la póliza (éste Id es igual para todos los vehiculos de esa casa)
```{r}
Data_noId <- train
Data_noId[,c("Row_ID","Household_ID","Vehicle","Calendar_Year","EdadVehiculo")] <- NULL
dim(Data_noId)

```
Tenemos vehículos duplicados pero cuyas Cat10,Cat11 y Cat12 varian en los diferentes año.

Correlación entre las variables:
```{r}
train_variables <- train[,5:34]
head(train_variables)
library(polycor)
hetcor(train_variables)
```


##Relaciona dos variables categóricas
cor(train$Calendar_Year,train$)
spineplot(train$Calendar_Year,train$Cat2)
spineplot(train$Calendar_Year,train$Cat3)
spineplot(train$Calendar_Year,train$Cat4)


##Muestra de Datos

El fichero "Train" que contiene datos de 2005, 2006 y 2007 tiene 13.184.290 observaciones y 35 columnas. De los cuales 95.605 han tenido siniestro con daño corporal.
```{r}
positiveclaim <- train[train$Claim_Amount>0,]
dim(positiveclaim)
```

Vamos a tomar una muestra del fichero "train" para trabajar los diferentes modelos y finalmente aplicarlo al fichero completo. Cogemos las 5.000.000 primeras filas.

```{r}
train_sample <- train[1:100000,]
class(train_sample)
train_sample <- as.data.frame(train_sample)
str(train_sample)
```


```{r}
library(plyr)
train_sample[6:20] <- lapply(train_sample[6:20], as.factor) 
train_sample$NVCat <- as.factor(train_sample$NVCat)
train_sample$OrdCat <- as.integer(train_sample$OrdCat)
train_sample$Model_Year <- as.factor(train_sample$Model_Year)
train_sample$Calendar_Year <- as.factor(train_sample$Calendar_Year)
```



Cuando el fichero ya está limpio lo divido en dos partes:

- 80000 observaciones "train"
- 20000 observaciones "test"

##KNN utilizando variables numéricas

```{r}
summary(train)
names(train_sample)
cols <- c("Cat8","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8")
claims <- c("classification")
data_num <-train_sample[,cols]
head(data_num)
data_num_labels <- train$Claim_Amount[1:100000]
data_num_labels <- ifelse(train$Claim_Amount==0,"0","1")
data_num_labels <- as.factor(data_num_labels)
train_set_labels <- data_num_labels[1:80000]
test_set_labels <- data_num_labels[80001:100000]
library(class)
train_set <-data_num[1:80000,] 
test_set <- data_num[80001:100000,]
summary(train_set)
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
train_set_norm <- as.data.frame(lapply(train_set,normalize))
test_set_norm <- as.data.frame(lapply(test_set,normalize))
test_set[is.na(test_set$Cat8),] <- "A"
train_set[is.na(train_set$Cat8),] <- "A"
summary(test_set$Cat8)

prediccion <- knn(train=train_set,test=test_set,cl=train_set_labels,k=15)
```

#Clasificación K-vecinos (KNN)

El algoritmo KNN requiere que todas las variables sean categóricas o continuas. Enel caso de tener de los dos tipos, las categóricas deben ser transformadas a numéricas antes de aplicar el algoritmo. En el caso de que las categóricas tengan más de dos categorías usaremos variables dummy.
cor(train_sample)
```{r}
library(caret)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
head(train_sample)
class(train_sample)

pruebaknn <- train_sample[,c("Var1","Var2","Var3","Var4")]
class(pruebaknn$Cat1)
levels <- train_sample[,35]

levels <- ifelse(levels==0,"0","1")
levels <- as.factor(levels)
unique(levels)
count(levels)

pruebaknn_train <- pruebaknn[1:4000000,]
pruebaknn_test <- pruebaknn[4000001:5000000,]

train_levels <- levels[1:4000000]
test_levels <- levels[4000001:5000000]
class(test_levels)
pred <- knn(train=pruebaknn_train,test=pruebaknn_test,cl=train_levels,k=3,use.all = FALSE)
header <- unlist(strsplit(colnames(dummies), '[.]'))[2 * (1:ncol(dummies))]
Cat1 <- factor(dummies %*% 1:ncol(dummies), labels = header)
```
str(train_sample)
* Necesitamos normalizar los datos
* El objetivo es clasificar los datos en "si" tienen daño corporal o "no" tiene daño corporal




#problema de memoria
library(pryr)

```{r}
memory.limit()
object_size(train)
memory.limit(size=16384)
```
##Substituimos el importe por 0 o 1 (no importe - si importe)
prueba <- train[sample(nrow(train), 100000), ]
sum(prueba$Claim_Amount)
prueba$damage <- ifelse(prueba$Claim_Amount==0,"0","1")
prueba$damage <- as.factor(prueba$damage)
sum(prueba$Claim_Amount!=0)
sum(prueba$Claim_Amount)

###Número de casos con daño corporal.
sum(train$Claim_Amount==0)
sum(train$Claim_Amount!=0)
sum(prueba$Claim_Amount!=0)

#Vamos a trabajar inicialmente sobre una muestra de 2 millones de observaciones:
````{r}
train_sample <- train[sample(nrow(train), 2000000), ]
train_sample <- as.data.frame(train_sample)
dim(train_sample)
str(train_sample)

```


#Comprobacion filas duplicadas
```{r}
anyDuplicated(train_sample)
train_sample[duplicated(train_sample),]
head(train_sample)
```
##densidad

```{r}
install.packages("tigerstats")
library(tigerstats)
quantile(train_sample$Claim_Amount)
summary(train_sample$Claim_Amount)
quantile(train_sample$Claim_Amount,probs=c(0.85,0.99,1))
nrow(train_sample)
positiveclaim <- train_sample[train_sample$Claim_Amount>0,]
nrow(positiveclaim)

##Correlaciones entre variables???
cor(train_sample$Var1,train_sample$Var2)
cor(train_sample$Var1,train_sample$Var6)
CrossTable(x=train_sample$Cat1,y=train_sample$Cat2)

#de 2000000 solo 14517 han tenido siniestro, esto es el 0.7%
densityplot(~Claim_Amount,data=train_sample,
       xlab="Importe Reclamacion",
       main="Densidad Reclamaciones")
boxplot(train_sample$Claim_Amount,main="Importe Siniestros Daño Corporal",ylab="Importe")
```

write.csv(train, file = "train_clean.csv")
#Tratamiento?
str(train)
summary(train_sample$Blind_Make)

