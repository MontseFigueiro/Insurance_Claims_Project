---
title: "Claim Car Insurance"
author: "Montse Figueiro & Aniana González"
date: "6 de julio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##
The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer's vehicle.


* Cada Fila contiene la información anual sobre el seguro de un vehículo.  
* La variable "Claim_Amount" ha sido ajustada para tener en cuenta los efectos de las características no correspondientes al vehículo, pero pueden tener interacciones interesantes con las variables del vehículo.
* "Calendar_Year" es el año en el que el vehículo fué asegurado.
* "Household_ID" es la identificación del hogar, en un hogar puede haber más de un vehículo asegurado.
* "Vehicle" es el número que identifica al vehículo, pero el mismo vehículo no tiene porque tener el mismo número en los diferentes años.
* Tenemos para identifiar el vehículo Model_Year, Blind_Make (manufacturer), Blind_Model, Blind_Submodel.
* El resto de columnas contienen características del vehículo así como, otras características asociadas a la poliza.
* Las variables numéricas han sido normalizadas, tienen media 0 y desviación standar 1.
* Tenemos dos datasets:
    + Training de 2005-2007 para construir el modelo
    + Test de 2008-2009 sobre el que realizaremos las predicciones.

##Objetivo del Estudio

* Problema de Clasificación

Determinar que vehículos asegurados tendrán siniestros con daño corporal en los años 2008-2009, para ello utilizaremos el training dataset que nos aporta la información correspondiente a los años 2005-2006-2007, el cual volveremos a dividir en dos partes Training y Test data set para poder contrastar los resultados de la clasificación. Por último aplicaremos el modelo al Test dataset para 2008-2009.

    + K-vecinos (necesario normalizar)
    + Arboles de decisión (no necesario normalizar)
    + Bayes (Aprendizaje Probabilistico)
    + Random Forest
    + Validación: ROC, 

* Problema de Regresión

El objetivo del estudio es conseguir predecir en función de las características del vehículo los pagos por daño corporal ocasionados anualmente por cada vehículo.

    + Random Forest Regresión.
    + Previsión Datos numéricos - Métodos de Regresión
        + GLM
        + LM (PCA)
        + SVM
        + GBM
    + Neutral Networks
    
* Validación: Caret, ROC (visualización), Cross-validation, jackknife

Tipicamente en Seguros aplicamos los siguientes métodos:

Decision Trees, Random Forests, Gradient Boosting Machines, Neural Networks and Support Vector Machines

##Code Book Variables

[Dictionary](https://kaggle2.blob.core.windows.net/competitions-data/kaggle/2509/dictionary.html?sv=2012-02-12&se=2016-09-11T09%3A28%3A10Z&sr=b&sp=r&sig=LDorwQLrH%2BUJeduG58UByqlaxlatNMpte4iJZLhM0V8%3D)




##Lectura de Datos
```{}
library(data.table)
train <- fread("train_set.csv")
test <- read.csv("test_set.csv")
str(train)
summary(train)
```

###problema de memoria

```{r}
memory.limit()
memory.limit(size=60000)
```

###Cambiamos los tipos de variables:

Las categóricas pasan a Factor: 
```{r}
class(train)
train <- as.data.frame(train)
```

```{r}
library(plyr)
train[6:20] <- lapply(train[6:20], as.factor) 
train$NVCat <- as.factor(train$NVCat)
train$OrdCat <- as.factor(train$OrdCat)
```
----------------------------
Tenemos el año de la póliza y el año del vehículo, hemos comprobado que ninguna de las variables numérica se corresponde con la antigûedad del coche pero podemos calcularla y puede ser un dato muy interesante:

```{r}
train$EdadVehiculo <- as.numeric(train$Calendar_Year-train$Model_Year)
```
Tenemos valores negativos en la edad del vehículo, es decir que si el año de la póliza es 2005 el año del modelo es 2006:
Tenemos 155.991 coches con edades negativas,las vamos a dejar a 0 porque no tiene lógica 

```{r}
train$EdadVehiculo <- ifelse(train$EdadVehiculo<0,0,train$EdadVehiculo)
```
------------------------------
Tratamos a los ? como NA:
```{r}
train[train=="?"] <- NA
```

Contamos los casos completos (no tienen ningún NA) y los casos incompletos (tienen algún NA)
```{r}
sum(complete.cases(train)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(train)) # Count of incomplete cases
```
Tenemos 9.457.989 observaciones con algún NA y 3.726.301 sin NA.
#Comprobacion filas duplicadas
```{r}
anyDuplicated(train)
train[duplicated(train),]
```

###Número de casos con daño corporal.
sum(train$Claim_Amount==0)
sum(train$Claim_Amount!=0)


##Visualización de NA's
```{r}
library(VIM)
library(mice)
```
##Visualización con VIM de las variables con NA:

Tabla resumen Missing Values por Variable:
```{r}
Tabla_NAs <- as.data.frame(sapply(train, function(x) sum(is.na(x))))
colnames(Tabla_NAs) <- c("NumNAs")
Tabla_NAs$Porcentaje <- round((Tabla_NAs$NumNAs/nrow(train))*100,2)
```
Tenemos en total 23.438.318 de Missing Values, en el campo Porcentaje se indica el tanto por ciento de NA's sobre el total de observaciones de esa variable.

Seleccionamos de la tabla solo las variables que tienen NAs:
```{r}
TablaNas_Positive <- Tabla_NAs[Tabla_NAs$NumNAs>0,]
```
Como hemos comprobado en nuestra tabla "TablaNAs_Positive" solamente las variables categóricas tienen Missing Values:

|Variable|Número de NA|Porcentaje|
|--------|------------|----------|
|Blind_Make|        8431  |     0.06|
|Blind_Model|       8431  |     0.06|
|Blind_Submodel|    8431  |     0.06|
|Cat1           |  25981  |     0.20|
|Cat2   |        4874164  |    36.97|
|Cat3    |          3999  |     0.03|
|Cat4     |      5631649  |    42.71|
|Cat5      |     5637321  |    42.76|
|Cat6     |        25981  |     0.20|
|Cat7     |      7167634  |    54.36|
|Cat8      |        3364  |     0.03|
|Cat10      |       3917  |     0.03|
|Cat11       |     31469  |     0.24|
|OrdCat       |     7546  |     0.06|


```{r}
cols <- rownames(TablaNas_Positive)
cols_with_NA <- train[,cols]
```

```{r}
jpeg("Missing_Pattern.jpeg")
train_aggr = aggr(cols_with_NA, numbers=TRUE, sortVars=TRUE, labels=names(cols_with_NA), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
dev.off()
```

##IMPUTACIÓN MISSING VALUES 

En Cat1, Cat2, Cat3, Cat4, Cat5, Cat6, Cat7, Cat8, Cat9 se da la circunstancia de que no varían para el mismo Blind_Submodel y Model_Year, son iguales independientemente de la póliza, del asegurado y de la household_ID, con lo que summarizamos esta información para reducir el caso de Missing Values que tenemos en el dataset:

###Agregamos Variables Categóricas por Submodel

```{r}
#El fichero train que se utiliza tiene los ? y no han sido sustituidos por NA porque sino aggregate los ignora.
submodel1 <- aggregate(Claim_Amount~Blind_Submodel+Cat1+Cat2+Cat3+Cat4+ Cat5+ Cat6+Cat7+Cat8+Cat9,train,sum)
submodel1[submodel1=="?"] <- NA
data<- submodel1[!is.na(submodel1$Blind_Submodel),]
data <- data[order(data$Blind_Submodel),]
#MICE no acepta más de 50 niveles, con lo que tenemos que quitar del dataset Blind_Submodel porque 
cols <- c("Claim_Amount","Cat1","Cat2","Cat3","Cat4", "Cat5", "Cat6", "Cat7", "Cat8","Cat9")
submodels <- data[,cols]
```
###Imputación Missing Values
```{r}

library(mice)
imp <- mice(data=submodels, m=5,maxit=20,method= "polyreg",MaxNWts = 2000)
imp2 <- mice(data=submodels, m=5,maxit=10,method= "polyreg",MaxNWts = 2000)
imp3 <- mice(data=submodels, m=10,maxit=10,method= "polyreg",MaxNWts = 2000)
modelFit <- with(imp,glm(Claim_Amount~ Cat1+Cat2+Cat3+Cat4+ Cat5+ Cat6+Cat7+Cat8+Cat9))
mi.reg.pool <- pool(modelFit)
modelFit
142300
summary(mi.reg.pool)
pool.r.squared(modelFit)

modelFit2 <- with(imp2,glm(Claim_Amount~ Cat1+Cat2+Cat3+Cat4+ Cat5+ Cat6+Cat7+Cat8+Cat9))
modelFit2
142400
mi.reg.pool2 <- pool(modelFit2)
summary(mi.reg.pool2)
pool.r.squared(modelFit2)

modelFit3 <- with(imp3,glm(Claim_Amount~ Cat1+Cat2+Cat3+Cat4+ Cat5+ Cat6+Cat7+Cat8+Cat9))
modelFit3
mi.reg.pool3 <- pool(modelFit3)
summary(mi.reg.pool3)
pool.r.squared(modelFit3)


coef <- modelFit$analyses


#Completamos los NA con los datos de las 5 imputaciones (la dimensión de la tabla es 5x6832)
datos <- complete(imp,action="long")

#Añadimos a la tabla original el mismo .id que nos da Mice que es el nombre de la fila (rowname)
data$.id <- rownames(data)

#Seleccionamos el valor más frecuente para cada categórica y para cada id.
Cat1 <- melt(as.table(with(datos,by(Cat1,.id,function(xx)names(which.max(table(xx)))))))
Cat2 <- melt(as.table(with(datos,by(Cat2,.id,function(xx)names(which.max(table(xx)))))))
Cat3 <- melt(as.table(with(datos,by(Cat3,.id,function(xx)names(which.max(table(xx)))))))
Cat4 <- melt(as.table(with(datos,by(Cat4,.id,function(xx)names(which.max(table(xx)))))))
Cat5 <- melt(as.table(with(datos,by(Cat5,.id,function(xx)names(which.max(table(xx)))))))
Cat6 <- melt(as.table(with(datos,by(Cat6,.id,function(xx)names(which.max(table(xx)))))))
Cat7 <- melt(as.table(with(datos,by(Cat7,.id,function(xx)names(which.max(table(xx)))))))
Cat8 <- melt(as.table(with(datos,by(Cat8,.id,function(xx)names(which.max(table(xx)))))))
Cat9 <- melt(as.table(with(datos,by(Cat9,.id,function(xx)names(which.max(table(xx)))))))

most_freq <- cbind(Cat1,Cat2$value,Cat3$value,Cat4$value,Cat5$value,Cat6$value,Cat7$value,Cat8$value,Cat9$value)
colnames(most_freq) <- c(".id","Cat1m","Cat2m","Cat3m","Cat4m","Cat5m","Cat6m","Cat7m","Cat8m","Cat9m")

datadf <- merge(data,most_freq,by=".id",all.x=TRUE) 
#Toca pasarlo a "train" para eso vamos a crear un id que va a ser la unión de Blind_Submodel+Cat1+Cat2.....Cat9, en las dos tablas para poder hacer el merge con train.
train[train=="?"] <- NA
train$ID <- paste(train$Blind_Submodel,train$Cat1,train$Cat2,train$Cat3,train$Cat4,train$Cat5,train$Cat6,train$Cat7,train$Cat8,train$Cat9,sep="")
datadf$ID <- paste(datadf$Blind_Submodel,datadf$Cat1,datadf$Cat2,datadf$Cat3,datadf$Cat4,datadf$Cat5,datadf$Cat6,datadf$Cat7,datadf$Cat8,datadf$Cat9,sep="")
train$ID <- as.factor(train$ID)
datadf$ID <- as.factor(datadf$ID)
datadf <- datadf[,13:22]
traindf <- train

traindf <- merge(traindf,datadf,by="ID",all.x = TRUE)

#Reemplazamos los NA con los valores que nos ha imputado MICE
traindf$Cat1[is.na(traindf$Cat1)] <- traindf$Cat1m[is.na(traindf$Cat1)]
traindf$Cat2[is.na(traindf$Cat2)] <- traindf$Cat2m[is.na(traindf$Cat2)]
traindf$Cat3[is.na(traindf$Cat3)] <- traindf$Cat3m[is.na(traindf$Cat3)]
traindf$Cat4[is.na(traindf$Cat4)] <- traindf$Cat4m[is.na(traindf$Cat4)]
traindf$Cat5[is.na(traindf$Cat5)] <- traindf$Cat5m[is.na(traindf$Cat5)]
traindf$Cat6[is.na(traindf$Cat6)] <- traindf$Cat6m[is.na(traindf$Cat6)]
traindf$Cat7[is.na(traindf$Cat7)] <- traindf$Cat7m[is.na(traindf$Cat7)]
traindf$Cat8[is.na(traindf$Cat8)] <- traindf$Cat8m[is.na(traindf$Cat8)]
#Seleccionamos las columnas que necesitamos, dejando las columnas que hemos utilizado para la limpieza del archivo.
traindf <- traindf[,2:36]

#Sustitución de los Modelos con NA por "Desconocido", recordamos que al abrir el fichero con fread nos elimina el tipo de variable y tenemos que volver a pasar a factor:
traindf$Blind_Make<- as.character(traindf$Blind_Make)
traindf$Blind_Make[is.na(traindf$Blind_Make)] <- "Desconocido"
traindf$Blind_Make<- factor(traindf$Blind_Make)

traindf$Blind_Model<- as.character(traindf$Blind_Model)
traindf$Blind_Model[is.na(traindf$Blind_Model)] <- "Desconocido"
traindf$Blind_Model<- factor(traindf$Blind_Model)

traindf$Blind_Submodel<- as.character(traindf$Blind_Submodel)
traindf$Blind_Submodel[is.na(traindf$Blind_Submodel)] <- "Desconocido"
traindf$Blind_Submodel<- factor(traindf$Blind_Submodel)
#Grabamos el fichero para no volver a tener que ejecutar todos los pasos previos de limpieza.
write.csv(traindf,"traindf.csv",row.names = FALSE)
```
CARGAMOS EL FICHERO TRAINDF YA LIMPIO PARA CONTINUAR A PARTIR DE AHÍ NUESTROS DIFERENTES ESTUDIOS:
```{r}
datos_train <- read.csv("traindf.csv")
Tabla_NAs_traindf <- as.data.frame(sapply(datos_train, function(x) sum(is.na(x))))
colnames(Tabla_NAs_traindf) <- c("NumNAs")
Tabla_NAs_traindf$Porcentaje <- round((Tabla_NAs_traindf$NumNAs/nrow(datos_train))*100,2)
TablaNas_Positive_traindf <- Tabla_NAs_traindf[Tabla_NAs_traindf$NumNAs>0,]
TablaNas_Positive_traindf
```
SELECCIONAMOS LOS CASOS COMPLETOS, HEMOS PASADO DE :
```{r}
casos_completos <- datos_train[complete.cases(datos_train),]#13141377
casos_completos$clasification <- as.factor(ifelse(casos_completos$Claim_Amount==0,"0","1"))
casos_completos_Claim <- casos_completos[casos_completos$Claim_Amount>0,]#95324
plot(casos_completos_Claim$Claim_Amount)
hist(casos_completos_Claim$Claim_Amount)
```
SPLIT DATAFRAME, TRAIN, VALIDATION AND TEST:
```{r}
set.seed(1234)
idx <- sample(seq(1, 3), size = nrow(casos_completos), replace = TRUE, prob = c(.6, .2, .2))
train <- casos_completos[idx == 1,]
test <- casos_completos[idx == 2,]
val <- casos_completos[idx == 3,]
prop.table(table(train$clasification))
prop.table(table(test$clasification))
prop.table(table(val$clasification))
```
GRABAMOS LOS FICHEROS TRAIN,TEST Y VALIDATION PARA SIEMPRE TOMAR LOS MISMOS REGISTROS:
```{r}
write.csv(train,"train_casos_completos.csv",row.names = FALSE)
write.csv(test,"test_casos_completos.csv",row.names=FALSE)
write.csv(val,"val_casos_completos.csv",row.names=FALSE)
```
ABRIMOS LOS FICHEROS:
```{r}
train <- read.csv("train_casos_completos.csv")
val <- read.csv("val_casos_completos.csv")
test <- read.csv("test_casos_completos.csv")
cols <- c("Calendar_Year", "Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "Cat10", "Cat11", "Cat12", "OrdCat", "Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "NVCat", "NVVar1", "NVVar2","NVVar3", "NVVar4", "clasification")
train <- train[,cols]
test <- test[,cols]
val <- val[,cols]
```
CLUSTER UNDER-SAMPLING FOR UNBALANCED DATA:

```{r}
train$clasification <- as.factor(train$clasification)
table(train$clasification)

```


MODELO SVM:
```{R}
library(e1071) 
mod.svm <- svm(clasification ~ ., data = train, kernel = "radial")
pred.test <- 
mod.svm <- svm(clasification ~ ., data = train_SMOTE, kernel = "radial")


```

mod.random <- randomForest(class ~ ., data = billetes.train)
mod.ctree <- ctree(class ~ ., data = billetes.train)
mod.gbm <- gbm(class ~ ., data = dat.gbm, interaction.depth = 6, n.trees = 10000, cv.folds = 3)
```
siupamos house+submodel+model_year nos da cuantas polizas diferentes tenemos en el dataset "train", muchas observaciones no son independientes se trata del mismo vehículo asegurado en diferentes años, pero hay variables que no se mantienen constantes (como Cat10, Cat11, Cat12):

```{r}
polizasdifcoches <-aggregate(Claim_Amount~Blind_Submodel+Model_Year+Household_ID,train,sum)#7.361.942 polizas pertenecen a coches diferentes, podría existir algún coche que un año estuviera asegurado en una casa y otro año en otra pero sería la excepción.
dim(polizasdifcoches)#7361942 no tiene en cuenta los NA en Blind_Submodel
```



train_aggr = aggr(train_2005, numbers=TRUE, sortVars=TRUE, labels=names(train_2005), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
train_2006 <- train[train$Calendar_Year==2006,]
dim(train_2006)
train_2007 <- train[train$Calendar_Year==2007,]
dim(train_2007)

##Problema con "Imbalanced Training Data", más del 99% de los datos están clasificados como 0.

Tanto en el fichero Train como en el de Casos_Completos el 99% de los datos está clasificado como 0 con lo que cualquie predicción que hagamos nos va a dar 0.

```{r}    
data <- train
```

```{r}
data$Claim_Amount <- ifelse(data$Claim_Amount==0,"0","1")
prop.table(table(data$Claim_Amount))
```    
El 99,27% de las observaciones no tienen daño corporal, el 0,73%.

Al existir umbalanced data nos interesa conocer los datos de los coches que tienen siniestro para perder la mínima información posible.

```{r}
siniestros <- train[train$Claim_Amount>0,]
siniestros_nocompletos <- siniestros[complete.cases(siniestros),]
dim(siniestros_nocompletos)
```

##Multicolinealidad entre variables.

Blind_Submodel unido a Model_Year nos da el modelo exacto del vehículo y para un mismo modelo las catégoricas desde Cat1 a Cat9 son iguales.

Modelo k.7.3
```{r}
modelok73 <- train[train$Blind_Submodel=="K.7.3",]
cols <- c("Blind_Submodel","Model_Year","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")
modelok73 <- modelok73[,cols]
head(modelok73)
uniquemodelok73 <-lapply(modelok73,unique)
```

Para visualizar mejor el número de modelos diferentes que tenemos unificamos en una sola variable Blind_Submodel y Model_Year:

```{r}
train$Model <- as.factor(ifelse(is.na(train$Blind_Submodel),train$Blind_Submodel,paste(train$Blind_Submodel, as.factor(train$Model_Year), sep='')))
````

Agregado del Modelo, número de observaciones para cada Modelo:
```{r}
modelos <- as.data.frame(train$Model)
modelos$count <- as.numeric(1)
agregado_modelos <- aggregate(count~`train$Model`,modelos,sum)
agregado_modelos$count <- as.numeric(agregado_modelos$count)
dim(agregado_modelos)
#Añadimos una fila con los NA que la función aggregate excluye
modelos_NA <- train[is.na(train$Model),]
dim(modelos_NA)
newrow <- c("NA",8431)
agregado_modelos <- rbind(agregado_modelos,newrow)
agregado_modelos$count <- as.numeric(agregado_modelos$count)
head(agregado_modelos[order(-agregado_modelos[,2]), ])
dim(agregado_modelos)
```

Agregado de Blind_Submodel, observaciones con más Claim_Amount:

```{r}
agregado_claim_amount <- aggregate(Claim_Amount~Blind_Submodel+Model_Year,train,sum)
head(agregado_claim_amount[order(-agregado_claim_amount[,3]), ])
dim(agregado_claim_amount)
```

##Problemas que nos encontramos en nuestra base de datos:

* Número elevado de Missing Values
* Multicolinealidad 
* Unbalanced Data. 99% Claim_Amount = 0.
    * Under-Sampling: Eliminamos observaciones = 0, solo vale para ahorrar tiempo, perdemos información.
    * Over-Sampling: Implica hacer copias de la Clase mínima causando overfitting.
    * Este no suele ser un problema para la regressión logística.
    * Métodos de penalización como Ridge o Lasso funcionan bien en regressiones binomial.
    * logit and probit aproximan el 0 al mismo ratio que el 1.

##knn para imputacion de missing values
```{r}
install.packages("scrime")
library(scrime)
cols <- c("Cat2","Cat7")
prueba <- train[,cols]
head(prueba)
prueba$Cat2 <- sapply(prueba$Cat2,switch,'A'=1,'B'=2,'C'= 3)
head(prueba)
knncatimpute()
```

##SELECCION VARIABLES

###Categóricas a dummies de los casos completos
entredf <- read.csv("entredf.csv")
head(entredf)
entredf$X <- NULL
dim(entredf)
```{r}
library(caret)
casos_completos <- train[complete.cases(train),]
dummies <- predict(dummyVars(~Cat1+Cat2+Cat3+Cat4+Cat5+Cat6+Cat7+Cat8+Cat9+Cat10+Cat11+Cat12+OrdCat+NVCat,data=casos_completos),newdata=casos_completos)
dummies <- as.data.frame(dummies)
entrenamiento <- cbind(casos_completos,dummies)
entrenamiento$clasificacion <- as.factor(ifelse(entrenamiento$Claim_Amount==0,"0","1"))
cols <- c("Calendar_Year","Model_Year" , "Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "NVVar1", "NVVar2", "NVVar3", "NVVar4", "Cat1.A", "Cat1.B", "Cat1.C","Cat1.D", "Cat1.E", "Cat1.F", "Cat1.G", "Cat1.H", "Cat1.I", "Cat1.J", "Cat2.A", "Cat2.B", "Cat2.C", "Cat3.A", "Cat3.B", "Cat3.C", "Cat3.D", "Cat3.E", "Cat3.F",  "Cat4.A","Cat4.B","Cat4.C", "Cat5.A", "Cat5.B", "Cat5.C", "Cat6.B", "Cat6.C", "Cat6.D", "Cat6.E", "Cat6.F", "Cat7.A", "Cat7.B","Cat7.C", "Cat7.D", "Cat8.A", "Cat8.B", "Cat8.C", "Cat9.A", "Cat9.B", "Cat10.A", "Cat10.B","Cat10.C","Cat11.A", "Cat11.B", "Cat11.C", "Cat11.D", "Cat11.E", "Cat11.F", "Cat12.", "Cat12.A", "Cat12.B", "Cat12.C", "Cat12.D", "Cat12.E", "Cat12.F", "OrdCat.1", "OrdCat.2", "OrdCat.3", "OrdCat.4","OrdCat.5", "OrdCat.6", "OrdCat.7", "NVCat.A", "NVCat.B", "NVCat.C", "NVCat.D", "NVCat.E","NVCat.F", "NVCat.G", "NVCat.H", "NVCat.I","NVCat.J", "NVCat.K", "NVCat.L", "NVCat.M", "NVCat.N","NVCat.O","clasificacion","Claim_Amount")
#dput(names(entrenamiento))

entredf <- entrenamiento[,cols]
write.csv(entredf,file="entredf.csv")
prop.table(table(entredf$clasificacion))
```

##Selección Variables sin corregir el desequilibrio en los datos, con CARET:
##Eliminar Variables Redundantes
```{r}
#Antes de evaluar la correlación, detectamos las variables con varianza 0.
varcero <- nearZeroVar(entredf,saveMetrics=TRUE)
str(varcero,vec.len=2)
#Variables con varianza 0:
varcero[varcero[,"zeroVar"]>0,]
#variables con varianza cerca a cero
varcero[varcero[,"zeroVar"]+varcero[,"nzv"]>0,]

##Penalized likelihood solution for not to remove this features:

library(dplyr)
library(glmnet)


y <- entredf[,"Claim_Amount"]
y <- as.vector(y)
x <- entredf
x$clasificacion <- NULL
x$Claim_Amount <- NULL
DF <- as.matrix(as.data.frame(lapply(x,as.numeric)))
output <- cv.glmnet(DF,y)
c <- coef(output,s='lambda.min',exact=TRUE)
inds <- which(c!=0)
variables <- row.names(c)[inds]
variables
[1] "(Intercept)"   "Calendar_Year" "Model_Year"    "Var7"          "Var8"          "NVVar1"       
 [7] "NVVar2"        "Cat1.B"        "Cat1.C"        "Cat1.E"        "Cat2.B"        "Cat3.B"       
[13] "Cat3.D"        "Cat3.F"        "Cat5.B"        "Cat6.B"        "Cat6.C"        "Cat6.D"       
[19] "Cat6.E"        "Cat6.F"        "Cat7.B"        "Cat7.C"        "Cat7.D"        "Cat9.A"       
[25] "Cat10.C"       "Cat11.B"       "Cat11.E"       "Cat12.D"       "Cat12.E"       "Cat12.F"      
[31] "OrdCat.3"      "OrdCat.4"      "NVCat.A"       "NVCat.E"       "NVCat.G"       "NVCat.H"      
[37] "NVCat.I"       "NVCat.J"       "NVCat.L"       "NVCat.N"       "NVCat.O"      

##randomForest- LVQ model BIGRF????
library(dplyr)
entredf_1 <- sample_n(entredf,100000)
library(randomForest)
entredf$Claim_Amount <- NULL
rf <- randomForest(clasificacion~.,data=entredf_1,importance=TRUE,ntree=100)
imp=importance(rf,type=1)
imp <- data.frame(predictors=rownames(imp),imp)
imp.sort <- arrange(imp,desc(X.IncMSE))
imp.sort$predictors <- factor(imp.sort$predictors,levels=imp.sort$predictors)
imp.3 <- imp.sort[1:30,]
imp.3
plot(rf,type=1)



z <- apply(entredf, 2, function(x) length(unique(x)) == 1)
dfr <- entredf[, !z]#entredf es nuestro dataset con los casos completos
n=length(colnames(dfr))#86 variables

#Calculamos la matriz de correlación
correlationMatrix <- cor(dfr[,1:85],use="complete.obs")

#Totalizamos la matriz de correlación
print(correlationMatrix)

#Encontramos las variables que estan muy correlacionadas (cutoff >0.7)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=(0.7),verbose = FALSE)

#Resultado variables altamente correlacionadas
print(highlyCorrelated)

#Variables importantes:

important_var=colnames(entredf[,-highlyCorrelated])
important_var
```
##Clasificar Variables por importancia

```{r}
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(clasificacion~., data=entredf, method="lvq", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
```
##FICHERO TEST ANALISIS DE DATOS

ANALIZAMOS LAS CATEGORICAS EN EL FICHERO TEST (no hay missing values)
Los NA han sido eliminados del fichero test, vamos a cruzar los modelos de coche de test con el train.

El número de niveles que tenemos en las categóricas no es el mismo para el test que para el train:
```{}
summary(train$Cat1)
summary(test$Cat1)
```
```{r}
test$Model <- as.factor(ifelse(is.na(test$Blind_Submodel),test$Blind_Submodel,paste(test$Blind_Submodel, as.factor(test$Model_Year), sep='')))
````

```{r}
cols <- c("Cat1", "Cat2", "Cat3", "Cat4","Cat5" "Cat6", "Cat7", "Cat8", "Cat9", "Cat10","Cat11", "Cat12", "OrdCat", "Model")
test2 <- test[,cols]
modelos_test <- as.data.frame(test2)
modelos_test$count <- as.numeric(1)

agregado_modelos_test <-aggregate(count~Model+Cat1+Cat4+Cat6+Cat7,modelos_test,sum)
agregado_modelos_test$count <- as.numeric(agregado_modelos_test$count)
anyDuplicated(agregado_modelos_test$Model)
####agregado_modelos_test[agregado_modelos_test$Model=="Z.27.21999",]
head(agregado_modelos_test[order(-agregado_modelos_test[,6]),])
dim(agregado_modelos_test)#Agregando por Model y las categóricas cat1+cat4+cat5+cat6+cat7 nos da el mismo número de modelos.

str(test$Model)#tenemos 3646 modelos diferentes

#Merge with train, vamos a detectar los casos en los que el Modelo coincide en el fichero test y en el fichero train:
y <- merge(x = train, y = agregado_modelos_test , by = "Model", all.x = TRUE)
head(y)
casos_coincidentes <- y[!is.na(y$count),]
d <- count(unique(casos_coincidentes$Model))
sum(d$freq)#modelos que estan en train y en test
f <-count(unique(train$Model))
sum(f$freq) #modelos totales en train
g <- count(unique(test$Model))
sum(g$freq)#modelos totales en test
sum(complete.cases(casos_coincidentes)) # 3.725.632 están completos
sum(!complete.cases(casos_coincidentes))#48967 tienen NA
```


```{r}
#De los Casos_coincidentes hay 48967 observaciones en train que tienen NA y que podemos corregir:
pruebamerge_NA <- casos_coincidentes[!complete.cases(casos_coincidentes),]
head(pruebamerge_NA)
sum(pruebamerge_NA$Claim_Amount)
```
##Tratamiento Missing values

Han sido borrados del Test dataset pero no del training dataset. Están como "?". 
¿¿Tenemos casillas en blanco???
Hay 4 variables con más de 4 millones de NA's


Hay 8431 observaciones con 48 siniestros con daño corporal a los que les falta Blind_Make, Blind_Model y Blind_Submodel:

```{r}
obs_without_model <- train[is.na(train$Blind_Submodel),]
dim(obs_without_model)
```

Sumamos cuantos NA tiene cada observación:
```{r}
NAS <- as.data.frame(rowSums(is.na(train)))
NAS$`rowSums(is.na(train))` <- as.factor(NAS$`rowSums(is.na(train))`)
```
3706301 casos no tienen NA y 3114961 tienen 1 NA.


VISUALIZACIÓN CON VIM DE SOLO LOS MISSING VALUES CASOS CON IMPORTE:
```{r}
library(VIM)
siniestros <- xy[xy$Claim_Amount>0,]
dput(names(xy))
cols <- c("Blind_Submodel", "Blind_Make", "Blind_Model", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5","Cat6", "Cat7", "Cat8", "Cat9", "Cat10", "Cat11", "Cat12", "OrdCat")
siniestros <- siniestros[,cols]
train_aggr = aggr(siniestros, numbers=TRUE, sortVars=TRUE, labels=names(siniestros), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
```


ESQUEMA A REALIZAR:

Train >>> casos_completos >>> Sample_casos_completos >>> Eliminar ID >>> Partición Train/Test >>> Oversampling >>> "Data Frame compensado" >>> Eliminar Variables



CARET, partimos la base de datos en dos:
```{r}
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(casos_completos$classification, p = .50,list = FALSE,times = 1)
train_sample <- casos_completos[ splitIndex,]
prop.table(table(train_sample$classification))
test_sample <- casos_completos[-splitIndex,]
test_sample_clas <- test_sample$classification
test_sample$classification <- NULL
```

SMOTE, over-resampling.

```{r}
library(DMwR)
train_SMOTE <- SMOTE(classification~.,train_sample,perc.over = 100,perc.under = 200)
prop.table(table(train_SMOTE$classification))
table(train_SMOTE$classification)
head(train_SMOTE)

```

--------------
ROSE para hacer el resampling de la base de datos, ,por defecto utiliza el método Both, una mezcla de Over and Under. El problema de ROSE son los datos que genera.
```{r}
library(ROSE)
train_ROSE <- ROSE(classification ~ ., data = train_sample, seed = 1)$data
table(train_ROSE$classification)
table(train_sample$classification)

```               
El train_sample tenía 20000 observaciones con 151 positivas. ROSE nos deja la base de datos con 10000 observaciones, las reduce pero nos amplia a 10000 las positivas.
--------------------

##Multicolinearidad de las variables, eliminación variables.

A partir de nuestra nueva base de datos creada con Rose y ya equilibrada, seleccionamos las variables que no tienen colinealidad:

CRAMER's V
```{r}
cv.test = function(x,y) {
  CV = sqrt(chisq.test(x, y, correct=FALSE)$statistic /
    (length(x) * (min(length(unique(x)),length(unique(y))) - 1)))
  print.noquote("Cramér V / Phi:")
  return(as.numeric(CV))
}

#Cramer V
with(train_SMOTE, cv.test(Cat1, Cat12))
```

correlationmatrix <- cor(train_SMOTE[,15:22])
correlationmatrix
highlyCorrelated <- findCorrelation(correlationmatrix, cutoff=0.5)
highlyCorrelated


Análisis modelos:

Blind_Submodel con más Claim_Amount:
```{r}
total_model <- aggregate(Claim_Amount~Blind_Submodel, train, sum)
Claim_model <- total_model[order(-total_model$Claim_Amount),] 
head(Claim_model,30)
```{r}
modeloau.14.0 <- train[train$Blind_Submodel=="AU.14.0",]
summary(modeloau.14.0)
```
Éste es el modelo de coche que más Claim_Amount tiene, hay 145474 observaciones. 
Con Summary vemos que Cat1, Cat4, Cat5, Cat7,Cat8,Cat9.















```{r}
require(plyr)
df1 <- ddply(casos_completos, c("Blind_Submodel","Cat1","Cat4","Cat5","Cat6","Cat7"), summarize, total=sum(Claim_Amount))
```

Categoricas:

```{r}
summary(train_SMOTE)
chisq.test(train_SMOTE$Cat4,train_SMOTE$Cat10)

#Interpretación Chi-test:
#Para las variables Cat10,Cat11 y Cat12 0.71,0.321 y 0.1287 no podemos rechazar la hipotesis nula de que las variables son independientes. Para el resto de las variables p-value es 0.

library(polycor)

pruebahetcor <- train_SMOTE[,c("Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")]
#Interpretación 
corrhetcor <- hetcor(pruebahetcor)
corrhetcor$correlations


oneway.test(casos_completos$Claim_Amount~casos_completos$Var1, var.equal = TRUE)
```
VIF variables numéricas:
```{r}
dput(names(train_SMOTE))
model <- glm(classification~Model_Year+ Cat9+ Cat10+ Var4+ Var5+Var8+ NVVar2+ NVVar3,train_SMOTE, family=binomial(link=logit))
summary(model)
pred <- predict(model,test_sample)
model$coefficients
anova(model,test="Chisq")
install.packages("pscl")
library(pscl)
pR2(model)


Rsq = summary(model)$r.squared
Rsq
1/(1-Rsq)
```




Podemos prescindir de las variables "Blind_Make" y "Blind_Model" porque están incluidas dentro de "Blind_Submodel", hemos comprobado que Blind_Submodel incluye esas variables:
```{r}
pruebasubmodel <- train[train$Blind_Submodel=="K.2.4",]
summary(pruebasubmodel)
```





##Encontrar patrones de los Missing Values con "mice"

Tenemos 8431 observaciones que tienen missing values en las variables "Blind_Make","Blind_Model" y "Blind_Submodel", para estas variables el número de niveles es muy elevado. Como máximo las variables pueden tener 50 categorías diferentes.

seleccionamos solo las columnas con Missing Values para encontrar patrones, todas las variables son categóricas (Factor).

```{r}
#Vamos a ignorar las 4 columnas que tienen un alto porcentaje de missing values, para poder imputar los missing values de las variables con menos del 5%.
#("Cat2","Cat4","Cat5","Cat7") #Variables con más del 5% de Missing Values
dput(names(train))
cols <- c("Row_ID", "Household_ID", "Vehicle", "Calendar_Year", "Model_Year", "Blind_Make", "Blind_Model","Blind_Submodel", "Cat1","Cat2", "Cat3", "Cat4","Cat5","Cat6","Cat7" ,"Cat8", "Cat9", "Cat10", "Cat11", "Cat12", "OrdCat", "Var1", "Var2","Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "NVCat", "NVVar1", "NVVar2", "NVVar3", "NVVar4", "Claim_Amount")
train2 <- train[,cols]
train2_complete <- train2[train2$Claim_Amount>0,]
dput(names(train2_complete))
train_ <- train2[,c("Calendar_Year", "Model_Year", "Cat1","Cat2", "Cat3", "Cat4","Cat5","Cat6","Cat7" ,"Cat8", "Cat9", "Cat10", "Cat11", "Cat12", "OrdCat", "Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "Claim_Amount")]
head(train_claim)

patron_train <- md.pattern(train_claim)
impclaim <- mice(data=train_, m=2,maxit = 3, method= "polyreg", seed = 1234,MaxNWts = 2000)
#hacemos la imputación solo para los que tienen importe de reclamación
```


```{r}
train_Missing_Values <- train[,cols]
train_NA_Claim <- train_Missing_Values[train_Missing_Values$Claim_Amount>0,]
train_Missing_Values_muestra <- train_Missing_Values[1:100000,]
patron_muestra <- md.pattern(train_Missing_Values_muestra)
patron_muestra
```

##Imputación de los Missing Value con MICE


```{r}
imp <- mice(data=train_NA_Claim, m=5,method= "polyreg", seed = 1234,MaxNWts = 2000)
summary(imp)
imp$imp$Cat6
imp$meth
completeData <- complete(imp,1)
library(lattice)
xyplot(imp,Claim_Amount ~Cat1+Cat2,pch=18,cex=1)
densityplot(tempData)
stripplot(tempData, pch = 20, cex = 1.2)
```
El paquete mice tarda en exceso, así que probamos otro de los paquetes de R "Amelia"

install.packages("Amelia")
library(Amelia)
imp.amelia <- amelia(train_Missing_Values_muestra, noms=colnames(train_Missing_Values_muestra))
Vemos que 317 coches tienen los datos completos desde Cat1 a Cat9.


Añadir columna clasificación:
```{r}
train$classification <- ifelse(train$Claim_Amount==0,"0","1")
train$classification <- as.factor(train$classification)
```
##Comprobación de datos normalizados en variables numéricas (nosotros no hemos realizado la normalización pero tenemos que conocer que ha sido hecha):

```{r}
var_col <- c("Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVVar1","NVVar2","NVVar3","NVVar4")
var_num <- train[,var_col]
round(sapply(var_num,function(x) mean(x)),0)
round(sapply(var_num,function(x) sd(x)),0)
```
##Visualización de Datos


Número de Pólizas por año
```{r}
count <- table(train$Calendar_Year)
df <- data.frame(group=names(count),count)
df$percent <-round((df$Freq/sum(df$Freq))*100,2)
df <- df[-1]
df
```
Pie Chart:
```{r}
slices <- df$Freq 
lbls <-df$Var1
pct <- df$percent
lbls <- paste("Año ",lbls, sep="")
lbls <- paste(lbls, pct,sep=": ") # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pct,labels = lbls, col=rainbow(length(lbls)),
  	main="Desglose Pólizas con Siniestro por Año")
```

Gráfico Variables categóricas - distribución tipo de variable:
```{r}
library(scales) 
gr2.a <- ggplot(train, aes(Cat1)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gr2.a + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()
```


summary(train$Row_ID)


Las 4 últimas variables no son variables del vehículo, con lo que se corresponden con variables de la póliza, podemos analizar en que casos la póliza ha tenido cobertura para daño corporal.
```{r}
claim_poliza <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza[order(-claim_poliza$Claim_Amount),])
dim(claim_poliza)
claim_poliza_amount <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = sum)
head(claim_poliza_amount[order(-claim_poliza_amount$Claim_Amount),])
claim_poliza_class <- aggregate(Claim_Amount ~ classification + NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza_class[order(-claim_poliza_class$Claim_Amount),])

```

##Eliminamos Vehículos Duplicados
Para ello quitamos las variables Id (Row_ID,Vehicle,Calendar_Year). Dejamos Household_ID para tener algún identificador de la póliza (éste Id es igual para todos los vehiculos de esa casa)
```{r}
Data_noId <- train
Data_noId[,c("Row_ID","Household_ID","Vehicle","Calendar_Year","EdadVehiculo")] <- NULL
dim(Data_noId)

```
Tenemos vehículos duplicados pero cuyas Cat10,Cat11 y Cat12 varian en los diferentes año.

Correlación entre las variables:
```{r}
train_variables <- train[,5:34]
head(train_variables)
library(polycor)
hetcor(train_variables)
```


##Relaciona dos variables categóricas
cor(train$Calendar_Year,train$)
spineplot(train$Calendar_Year,train$Cat2)
spineplot(train$Calendar_Year,train$Cat3)
spineplot(train$Calendar_Year,train$Cat4)


##Muestra de Datos

El fichero "Train" que contiene datos de 2005, 2006 y 2007 tiene 13.184.290 observaciones y 35 columnas. De los cuales 95.605 han tenido siniestro con daño corporal.
```{r}
positiveclaim <- train[train$Claim_Amount>0,]
dim(positiveclaim)
```


##KNN 

```{r}
prediccion <- knn(train=train_set,test=test_set,cl=train_set_labels,k=15)
```

#Clasificación K-vecinos (KNN)

El algoritmo KNN requiere que todas las variables sean categóricas o continuas. Enel caso de tener de los dos tipos, las categóricas deben ser transformadas a numéricas antes de aplicar el algoritmo (dummies). En el caso de que las categóricas tengan más de dos categorías usaremos variables dummy.
cor(train_sample)
```{r}
library(caret)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
head(train_sample)
class(train_sample)

pruebaknn <- train_sample[,c("Var1","Var2","Var3","Var4")]
class(pruebaknn$Cat1)
levels <- train_sample[,35]

levels <- ifelse(levels==0,"0","1")
levels <- as.factor(levels)
unique(levels)
count(levels)

pruebaknn_train <- pruebaknn[1:4000000,]
pruebaknn_test <- pruebaknn[4000001:5000000,]

train_levels <- levels[1:4000000]
test_levels <- levels[4000001:5000000]
class(test_levels)
pred <- knn(train=pruebaknn_train,test=pruebaknn_test,cl=train_levels,k=3,use.all = FALSE)
header <- unlist(strsplit(colnames(dummies), '[.]'))[2 * (1:ncol(dummies))]
Cat1 <- factor(dummies %*% 1:ncol(dummies), labels = header)
```

##densidad

```{r}
install.packages("tigerstats")
library(tigerstats)
quantile(train_sample$Claim_Amount)
summary(train_sample$Claim_Amount)
quantile(train_sample$Claim_Amount,probs=c(0.85,0.99,1))
nrow(train_sample)
positiveclaim <- train_sample[train_sample$Claim_Amount>0,]
nrow(positiveclaim)

##Correlaciones entre variables???
cor(train_sample$Var1,train_sample$Var2)
cor(train_sample$Var1,train_sample$Var6)
CrossTable(x=train_sample$Cat1,y=train_sample$Cat2)

#de 2000000 solo 14517 han tenido siniestro, esto es el 0.7%
densityplot(~Claim_Amount,data=train_sample,
       xlab="Importe Reclamacion",
       main="Densidad Reclamaciones")
boxplot(train_sample$Claim_Amount,main="Importe Siniestros Daño Corporal",ylab="Importe")
```


