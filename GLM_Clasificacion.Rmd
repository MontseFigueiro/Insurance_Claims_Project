---
title: "GLM_Clasificacion"
author: "Aniana González & Montse Figueiro"
date: "25 de octubre de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#CLASIFICACIÓN CON GLM

Los modelos lineales se basan en los siguientes supuestos:

1. Los errores se distribuyen normalmente.
2. La varianza es constante.
3. La variable dependiente se relaciona linealmente con la(s) variable(s) independiente(s). 

Los GLM son una extensión de los modelos lineales que permiten
utilizar distribuciones no normales de los errores (binomiales, Poisson, gamma, etc)
y varianzas no constantes. 

#Carga de ficheros

```{r}
train <- read.csv("traindf.csv")
test <- read.csv("testdf.csv")
train_downSample <- read.csv("train_downSample.csv")
memory.limit(size=60000)
train$clasification <- as.factor(ifelse(train$Claim_Amount==0,"0","1"))
train$clasification <- as.factor(train$clasification)
test$clasification <- as.factor(ifelse(test$Claim_Amount==0,"0","1"))
test$clasification <- as.factor(test$clasification)
```

#Nos quedamos con las columnas que necesitamos para el modelo

```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1", "Var2", "Var3", "Var4", "Var5", "Var6","Var7", "Var8", "NVCat", "NVVar1", "NVVar2", "NVVar3", "NVVar4","Claim_Amount","clasification")

train_glm <- train[,cols]
head(train_glm)
```

#Nos quedamos con las columnas que necesitamos del test
```{r}
cols <- c("Model_Year","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8",
          "Cat9","OrdCat","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVCat","NVVar1",
          "NVVar2","NVVar3","NVVar4")

test_glm <- test[,cols]
test_clas <- test[,"clasification"]
```


#Visualizamos las caracteristicas de los ficheros

```{r}
head(train)
head(train_glm)
head(test)
head(test_glm)
head(train_downSample)
```

#Hacemos el model GLM para predecir si va a existir daño corporal o no. Utilizamos el fichero con los datos agregados pero sin balancear.

Nos da como resultado un AIC de 335.472
Calculamos R^2 dandonos como resultado 0.2720185

```{r}
model_train_clas=glm(clasification~ Model_Year+
Cat1+ Cat2+ Cat3+ Cat4+Cat5+Cat6+Cat7+Cat8+Cat9+OrdCat+Var1+Var2+Var3+Var4+Var5+Var6+Var7+Var8+ NVCat+NVVar1+NVVar2+NVVar3+NVVar4, data=train_glm,family=binomial(link="logit"))
summary(model_train_clas)
```
Calculamos R^2

```{r}
#R^2 
1 - (deviance(model_train_clas)/model_train_clas$null.deviance)

```
Aplicamos el modelo al fichero test y validamos

```{r}
test_glm$clasification <- NULL
test_glm$prediccion=predict(model_train_clas, newdata=test_glm, type="response")
clasificacion_test <- ifelse(test_glm$prediccion < 0.5,0,1)
table(clasificacion_test,test_clas)
```
Tabla de clasificación

|    |no | si|
|----|---|----|
|no|2170698|16607|
|si|1101046|7216 |

Accuracy:

True Positive+ True Negative / Total Observations

```{r}
((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[1]))/(nrow(test_glm))
```
*0.6608617*

Precisión:
True Positives / (True Positives + False Positives).

```{r}
((table(clasificacion_test,test_clas)[4]))/((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[3]))
```
*0.3029006*

Recall:
True Positives / (True Positives + False Negatives).

```{r}
((table(clasificacion_test,test_clas)[4]))/((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[2]))
```
*0.006511096*

#Curva ROC sobre el test

```{r}
Pred_auxiliar_test= prediction(test_glm$prediccion, clasificacion_test, label.ordering = NULL)
class(Pred_auxiliar_test)
auc.tmp_test = performance(Pred_auxiliar_test, "auc")
auc_model_train_clas_test = as.numeric(auc.tmp_test@y.values)
auc_model_train_clas_test

CURVA_ROC_model_train_clas_test <- performance(Pred_auxiliar_test,"tpr","fpr")
plot(CURVA_ROC_model_train_clas_test,colorize=TRUE)
abline(a=0,b=1)
```

#Hacemos el model GLM para predecir si va a existir daño corporal o no. Utilizamos el fichero con los datos balanceados y agregados.

Nos da como resultado un AIC de 139.578
Calculamos R^2 dandonos como resultado 0.299275

```{r}
model_down_clas=glm(Class ~ Model_Year+
Cat1+ Cat2+ Cat3+ Cat4+Cat5+Cat6+Cat7+Cat8+Cat9+OrdCat+Var1+Var2+Var3+Var4+Var5+Var6+Var7+Var8+ NVCat+NVVar1+NVVar2+NVVar3+NVVar4, data=train_downSample,family=binomial(link="logit"))
summary(model_down_clas)
```

#R^2 
1 - (deviance(model_down_clas)/model_down_clas$null.deviance)

```
Aplicamos el modelo al fichero test y validamos

```{r}
test_glm$clasification <- NULL
test_glm$prediccion=predict(model_down_clas, newdata=test_glm, type="response")
clasificacion_test <- ifelse(test_glm$prediccion < 0.5,0,1)
table(clasificacion_test,test_clas)
```
Tabla de clasificación

|    |no | si|
|----|---|----|
|no|624705|5790|
|si|2647039|18033|

Accuracy:

True Positive+ True Negative / Total Observations

```{r}
((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[1]))/(nrow(test_glm))
```
*0.1950311*

Precisión:
True Positives / (True Positives + False Positives).

```{r}
((table(clasificacion_test,test_clas)[4]))/((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[3]))
```
*0.7569576*

Recall:
True Positives / (True Positives + False Negatives).

```{r}
((table(clasificacion_test,test_clas)[4]))/((table(clasificacion_test,test_clas)[4])+(table(clasificacion_test,test_clas)[2]))
```
*0.006766421*

#Curva ROC sobre el test

```{r}
Pred_auxiliar_test= prediction(test_glm$prediccion, clasificacion_test, label.ordering = NULL)
class(Pred_auxiliar_test)
auc.tmp_test = performance(Pred_auxiliar_test, "auc")
auc_model_down_clas_test = as.numeric(auc.tmp_test@y.values)
auc_model_down_clas_test

CURVA_ROC_model_down_clas_test <- performance(Pred_auxiliar_test,"tpr","fpr")
plot(CURVA_ROC_model_down_clas_test,colorize=TRUE)
abline(a=0,b=1)
```
