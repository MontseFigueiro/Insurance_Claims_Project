---
title: "Clasificación con Naive Bayes"
author: "Montse Figueiro & Aniana González"
date: "20 de octubre de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## CLASIFICACIÓN CON NAIVE BAYES

El método de clasificación Naive Bayes asume que todas las variables son independientes. El algoritmo de Bayes trabaja de la siguiente forma:

- Convierte el dataset en una tabla de frecuencias, para cada tipo de vehículo el número de veces que aparece con clasificación 1 o 0.
- Crea una tabla con las probabilidades a partir de las frecuencias.
- Calcula la probabilidad para cada clase, tendremos dos columnas 0 y 1 y los valores serán las probabilidades para cada observación, el valor más grande es el outcome de la predicción.

###Carga librarias

```{r}
library(e1071)
```

###Carga de Ficheros y creación variable "clasification"
```{r}
train <- read.csv("traindf.csv")
train$clasification <- as.factor(ifelse(train$Claim_Amount!=0,"1","0"))
test <- read.csv("testdf.csv")
test$clasification <- as.factor(ifelse(test$Claim_Amount!=0,"1","0"))
train_down <- read.csv("train_downSample.csv")
train_down$clasification <- as.factor(ifelse(train_down$Claim_Amount!=0,"1","0"))
```

##CLASIFICACIÓN CON NAIVE BAYES

###CARACTERISTICAS DEL VEHÍCULO Y DE LA POLIZA

###Bayes con Datos Desequilibrados

Nuestro DataSet no está equilibrado más del 95% de las observaciones son clasification=0, esto genera problemas a la hora de calcular los modelos y clasificar puesto que cualquier modelo tenderá a poner el valor de la clase mayoritaria.

```{r}
cols <-c("Blind_Submodel","Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "NVCat", "NVVar1", "NVVar2", "NVVar3", "NVVar4", "clasification")
bayes1 <- train[,cols]
```

Pasamos las numéricas a categóricas con los datos que nos proporcionan los quantiles:
```{r}
quantiles <- as.vector(quantile(bayes1$Var1, prob = seq(0, 1, length = 11), type = 5))
quantiles2 <- as.vector(quantile(bayes1$Var2, prob = seq(0, 1, length = 11), type = 5))
quantiles3 <- as.vector(quantile(bayes1$Var3, prob = seq(0, 1, length = 11), type = 5))
quantiles4 <- as.vector(quantile(bayes1$Var4, prob = seq(0, 1, length = 11), type = 5))
quantiles5 <- as.vector(quantile(bayes1$Var5, prob = seq(0, 1, length = 11), type = 5))
quantiles6 <- as.vector(quantile(bayes1$Var6, prob = seq(0, 1, length = 11), type = 5))
quantiles7 <- as.vector(quantile(bayes1$Var7, prob = seq(0, 1, length = 11), type = 5))
quantiles8 <- as.vector(quantile(bayes1$Var8, prob = seq(0, 1, length = 11), type = 5))

bayes1$Var1cat <- cut(bayes1$Var1,breaks=c(-Inf,-2.578222, -0.9230164, -0.7141069, -0.6176872, -0.4569876, -0.3605679, -0.1195186, 0.1777756, 0.5875594, 1.447302, 5.143392,Inf),quantiles=FALSE,labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var2cat <- cut(bayes1$Var2,breaks=c(-Inf,-2.493393, -1.231139, -0.9890633, -0.7296962, -0.5222025, -0.2109619,0.0484052, 0.2213167, 0.740051, 1.17233, 7.82942,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var3cat <- cut(bayes1$Var3,breaks=c(-Inf,-2.790335, -1.239933, -1.05481, -0.7771261, -0.4531614, -0.3143194, 
0.0096453, 0.3336099, 1.097241, 1.583188, 5.5633254,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var4cat <- cut(bayes1$Var4,breaks=c(-Inf,-2.508216, -1.205861, -0.9521559, -0.6984504, -0.5293134, -0.1910394, 
0.1472346, 0.3163716, 0.6546456, 1.246625, 7.589263,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var5cat <- cut(bayes1$Var5,breaks=c(-Inf,-3.350344, -1.078535, -0.8347024, -0.5968167, -0.2637767, -0.1150981, 
0.0692634, 0.384462, 0.6461363, 1.597679, 4.018167,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var6cat <- cut(bayes1$Var6,breaks=c(-Inf,-2.376657, -1.196419, -0.8934643, -0.6501645, -0.4700292, -0.2723481, 
-0.0033148, 0.3089978, 0.6411955, 1.399168, 4.584289,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var7cat <- cut(bayes1$Var7,breaks=c(-Inf,-2.778491, -1.13195, -0.9599238, -0.8616229, -0.763322, -0.5544326, 
0.2688375, 0.6128907, 0.9938067, 1.374723, 4.127148,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Var8cat <- cut(bayes1$Var8,breaks=c(-Inf,-2.163042, -1.006532, -0.7759298, -0.563355919999999, -0.4176654, 
-0.2781884, -0.109470489999998, 0.1194577, 0.5016793, 1.01036, 47.35074,Inf) ,labels=c("A","B","C","D","E","F","G","H","I","J","K","L"))
bayes1$Model_Year <- as.factor(bayes1$Model_Year)
bayes1$OrdCat <- as.factor(bayes1$OrdCat)
bayes1$NVCat <- as.factor(bayes1$NVCat)
bayes1$NVVar1 <- as.factor(bayes1$NVVar1)
bayes1$NVVar2 <- as.factor(bayes1$NVVar2)
bayes1$NVVar3 <- as.factor(bayes1$NVVar3)
bayes1$NVVar4 <- as.factor(bayes1$NVVar4)
```

Creamos el Modelo a partir del fichero Train Agregado:
```{r}
colsbayes1 <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat","NVCat","NVVar1","NVVar2","NVVar3","NVVar4")
trainbayes1 <- bayes1[,colsbayes1]
bayes1_class <- as.factor(bayes1[,"clasification"])
modelo_bayes1 <- naiveBayes(trainbayes1,bayes1_class)
```
Aplicamos el Modelo al fichero train y validamos:
```{r}
pred_bayes1 <- predict(modelo_bayes1,trainbayes1)
table(pred_bayes1,bayes1_class)
```

CONFUSION MATRIX:

|    |no | si|
|----|---|----|
|no|58309|42831|
|si|37663|28951|

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayes1,bayes1_class)[4])+(table(pred_bayes1,bayes1_class)[1]))/(nrow(trainbayes1))
```
*0.8833004*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayes1,bayes1_class)[4]))/((table(pred_bayes1,bayes1_class)[4])+(table(pred_bayes1,bayes1_class)[3]))
```
*0.4033184*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayes1,bayes1_class)[4]))/((table(pred_bayes1,bayes1_class)[4])+(table(pred_bayes1,bayes1_class)[2]))
```
*0.4346083*

*Nos ha clasificado 28951 de clase=1 correctamente y 37663 incorrecamente*
*Obtenemos un Accuracy elevado porque se trata de un dataset con una clase mayoritaria = 0 de más del 95% de los datos*

###MODELO APLICADO A TEST

Cambiamos Tipo de Variables Continuas a categóricas en el fichero Test:
```{r}
test_bayes <- test
test_bayes$Var1cat <- cut(test_bayes$Var1,breaks=c(-Inf,-2.578222, -0.9230164, -0.7141069, -0.6176872, -0.4569876, -0.3605679, -0.1195186, 0.1777756, 0.5875594, 1.447302, 5.143392,Inf),quantiles=FALSE,labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var2cat <- cut(test_bayes$Var2,breaks=c(-Inf,-2.493393, -1.231139, -0.9890633, -0.7296962, -0.5222025, -0.2109619,0.0484052, 0.2213167, 0.740051, 1.17233, 7.82942,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var3cat <- cut(test_bayes$Var3,breaks=c(-Inf,-2.790335, -1.239933, -1.05481, -0.7771261, -0.4531614, -0.3143194, 0.0096453, 0.3336099, 1.097241, 1.583188, 5.5633254,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var4cat <- cut(test_bayes$Var4,breaks=c(-Inf,-2.508216, -1.205861, -0.9521559, -0.6984504, -0.5293134, -0.1910394, 0.1472346, 0.3163716, 0.6546456, 1.246625, 7.589263,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var5cat <- cut(test_bayes$Var5,breaks=c(-Inf,-3.350344, -1.078535, -0.8347024, -0.5968167, -0.2637767, -0.1150981, 0.0692634, 0.384462, 0.6461363, 1.597679, 4.018167,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var6cat <- cut(test_bayes$Var6,breaks=c(-Inf,-2.376657, -1.196419, -0.8934643, -0.6501645, -0.4700292, -0.2723481, -0.0033148, 0.3089978, 0.6411955, 1.399168, 4.584289,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var7cat <- cut(test_bayes$Var7,breaks=c(-Inf,-2.778491, -1.13195, -0.9599238, -0.8616229, -0.763322, -0.5544326, 0.2688375, 0.6128907, 0.9938067, 1.374723, 4.127148,Inf),labels = c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$Var8cat <- cut(test_bayes$Var8,breaks=c(-Inf,-2.163042, -1.006532, -0.7759298, -0.563355919999999, -0.4176654, 
-0.2781884, -0.109470489999998, 0.1194577, 0.5016793, 1.01036, 47.35074,Inf) ,labels=c("A","B","C","D","E","F","G","H","I","J","K","L"))
test_bayes$NVVar1 <- as.factor(test_bayes$NVVar1)
test_bayes$NVVar2 <- as.factor(test_bayes$NVVar2)
test_bayes$NVVar3 <- as.factor(test_bayes$NVVar3)
test_bayes$NVVar4 <- as.factor(test_bayes$NVVar4)
test_bayes$Model_Year <- as.factor(test_bayes$Model_Year)
test_bayes$OrdCat <- as.factor(test_bayes$OrdCat)
```

Fichero Test separamos la variable "Clasification" en un vector aparte para poderlo cruzar con los datos que nos prediga el modelo:
```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat", "NVCat", "NVVar1", "NVVar2", "NVVar3", "NVVar4")
test_NB <- test_bayes[,cols]
testresult <- as.factor(test_bayes[,"clasification"])
```

Aplicamos el Modelo de Naive Bayes al fichero Test:
```{r}
pred_bayestest <- predict(modelo_bayes1,test_NB)
table(pred_bayestest,testresult)
```

Tabla de Clasificación:

|    |no | si|
|----|---|----|
|no|1837707|13632|
|si|1434037|10191|

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayestest,testresult)[4])+(table(pred_bayestest,testresult)[1]))/(nrow(test_NB))
```
*0.5607223*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayestest,testresult)[4]))/((table(pred_bayestest,testresult)[4])+(table(pred_bayestest,testresult)[3]))
```
*0.4277799*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayestest,testresult)[4]))/((table(pred_bayestest,testresult)[4])+(table(pred_bayestest,testresult)[2]))
```
*0.007056365*

##SOLO CON LAS CARACTERÍSTICAS DEL VEHÍCULO

En éste caso no tenemos en cuenta las características de la póliza para hacer la predicción, incluimos la proporción de vehículos con y sin daños corporal para cada observación diferente:

```{r}
cols <- c( "Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat","clasification")
bayes2 <- bayes1[,cols]
```

```{r}
colsbayes <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat")
train_aggr <- bayes2[,colsbayes]
class_aggr <- as.factor(bayes2[,"clasification"])
modelo_bayes_aggr <- naiveBayes(train_aggr,class_aggr)
```
Aplicamos el Modelo al fichero train y validamos:
```{r}
pred_bayes_aggr <- predict(modelo_bayes_aggr,train_aggr)
table(pred_bayes_aggr,class_aggr)
```
Tabla de Clasificación:

|    |no | si  |
|----|---|-----|
|no|569063|59114|
|si|48909|12668|

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayes_aggr,class_aggr)[4])+(table(pred_bayes_aggr,class_aggr)[1]))/(nrow(train))
```
*0.8433891*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayes_aggr,class_aggr)[4]))/((table(pred_bayes_aggr,class_aggr)[4])+(table(pred_bayes_aggr,class_aggr)[3]))
```
*0.1764788*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayes_aggr,class_aggr)[4]))/((table(pred_bayes_aggr,class_aggr)[4])+(table(pred_bayes_aggr,class_aggr)[2]))
```
*0.2057262*


Aplicamos el Modelo de Naive Bayes al fichero Test:

```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat")
test_NB2 <- test_bayes[,cols]
pred_bayestest2 <- predict(modelo_bayes_aggr,test_NB2)
table(pred_bayestest2,testresult)
```
Tabla de Clasificación:

|    |no | si |
|----|---|----|
|no|2792867|19609|
|si|478877|4214|

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayestest2,testresult)[4])+(table(pred_bayestest2,testresult)[1]))/(nrow(test_NB2))
```
*0.8487404*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayestest2,testresult)[4]))/((table(pred_bayestest2,testresult)[4])+(table(pred_bayestest2,testresult)[3]))
```
*0.1768879*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayestest2,testresult)[4]))/((table(pred_bayestest2,testresult)[4])+(table(pred_bayestest2,testresult)[2]))
```
*0.008722994*

##UNDER-SAMPLING FOR UNBALANCED DATA

Al tener suficiente número de observaciones lo más eficiente para después poder aplicar los diferentes métodos de Machine Learning es reducir las observaciones de la clase mayoritaria, en éste caso, los que no han tenido siniestro con daño corporal. 


Del fichero train seleccionamos todas las observaciones con clasificación = 1 y una muestra aleatoria de la clase mayoritaria para equilibrar el fichero:
```{r}
#El fichero lo voy a dividir en dos grupos la clase minoritaria y la mayoritaria:
train_major_class <- bayes1[bayes1$clasification=="0",]
train_minor_class <- bayes1[bayes1$clasification!="0",]
sample_major_class <- train_major_class[sample(nrow(train_major_class),nrow(train_minor_class),replace=FALSE),]
train_balanced <- rbind(train_minor_class,sample_major_class)
prop.table(table(train_balanced$clasification))
```

```{r}
colsbayes1 <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat","NVCat","NVVar1","NVVar2","NVVar3","NVVar4")
trainbayes1 <- bayes1[,colsbayes1]
bayes1_class <- as.factor(bayes1[,"clasification"])
modelo_bayes_aggr <- naiveBayes(trainbayes1,bayes1_class)
```


Aplicamos el Modelo al fichero train y validamos:
```{r}
pred_bayes1 <- predict(modelo_bayes_aggr,trainbayes1)
table(pred_bayes1,bayes1_class)
```

```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat","NVCat","NVVar1","NVVar2","NVVar3","NVVar4")
train_bayes_balanced <- train_balanced[,cols]
class_balanced <- as.factor(train_balanced[,"clasification"])
modelo_bayes_balanced <- naiveBayes(train_bayes_balanced,class_balanced)
```

Aplicamos el Modelo al fichero train y validamos:
```{r}
pred_bayes_balanced <- predict(modelo_bayes_balanced,train_bayes_balanced)
table(pred_bayes_balanced,class_balanced)
```
Tabla de Clasificación:

|    |no | si  |
|----|---|-----|
|no|39215|32298|
|si|32005|38922|

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayes_balanced,class_balanced)[4])+(table(pred_bayes_balanced,class_balanced)[1]))/(nrow(train_bayes_balanced))
```
*0.5485608*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayes_balanced,class_balanced)[4]))/((table(pred_bayes_balanced,class_balanced)[4])+(table(pred_bayes_balanced,class_balanced)[3]))
```
*0.5465038*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayes_balanced,class_balanced)[4]))/((table(pred_bayes_balanced,class_balanced)[4])+(table(pred_bayes_balanced,class_balanced)[2]))
```
*0.5487614*

Aplicamos el Modelo de Naive Bayes al fichero Test:

```{r}
cols <- c("Model_Year", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5", "Cat6", "Cat7", "Cat8", "Cat9", "OrdCat", "Var1cat", "Var2cat", "Var3cat", "Var4cat", "Var5cat", "Var6cat", "Var7cat", "Var8cat","NVCat","NVVar1","NVVar2","NVVar3","NVVar4")
test_NB_balanced <- test_bayes[,cols]
testresult_balanced <- test_bayes[,"clasification"]
pred_bayestest_balanced <- predict(modelo_bayes_balanced,test_NB_balanced)
table(pred_bayestest_balanced,testresult_balanced)
```

Tabla de Clasificación:

|  |0     | 1    |
|--|-------|-------|
|0|1200050|11562  |
|1|879331 |12228  |
  
Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_bayestest_balanced,testresult_balanced)[4])+(table(pred_bayestest_balanced,testresult_balanced)[1]))/(nrow(test_NB_balanced))
```
*0.57642049*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_bayestest_balanced,testresult_balanced)[4]))/((table(pred_bayestest_balanced,testresult_balanced)[4])+(table(pred_bayestest_balanced,testresult_balanced)[3]))
```
*0.5139975*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_bayestest_balanced,testresult_balanced)[4]))/((table(pred_bayestest_balanced,testresult_balanced)[4])+(table(pred_bayestest_balanced,testresult_balanced)[2]))
```
*0.01377153*

###Calibración de probabilidades

```{r}
pred_bayestest_balanced <- predict(modelo_bayes_balanced,test_NB_balanced,type = "raw")
pred <- as.data.frame(pred_bayestest_balanced)
```

Si cogemos que la probabilidad de corte para que sea clasificación=1 (tiene daño corporal) que la probabilidad sea > que 0.5:
```{r} 
pred_50 <- as.factor(ifelse(pred$`1`>0.5,"1","0"))
table(pred_50,testresult)
```

|  |0     | 1    |
|--|-------|-------|
|0|1200050|11562  |
|1|879331 |12228  |

Si cogemos que la probabilidad de corte para que sea clasificación=1 (tiene daño corporal) que la probabilidad sea > que 0.6:
```{r}
pred_60 <- as.factor(ifelse(pred$`1`>0.6,"1","0"))
table(pred_60,testresult)
```

|  |0     | 1    |
|--|-------|-------|
|0|1506515|15368  |
|1|572866 |8422  |

Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_60,testresult)[4])+(table(pred_60,testresult)[1]))/(nrow(pred))
```
*0.7203109*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_60,testresult)[4]))/((table(pred_60,testresult)[4])+(table(pred_60,testresult)[3]))
```
*0.3540143*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_60,testresult)[4]))/((table(pred_60,testresult)[4])+(table(pred_60,testresult)[2]))
```
*0.01448852*

Si cogemos que la probabilidad de corte para que sea clasificación=1 (tiene daño corporal) que la probabilidad sea > que 0.7:
```{r}
pred_70 <- as.factor(ifelse(pred$`1`>0.7,"1","0"))
table(pred_70,testresult)
```

|  |0     | 1    |
|--|-------|-------|
|0|1776130|18923 |
|1|303251 |4867  |


Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_70,testresult)[4])+(table(pred_70,testresult)[1]))/(nrow(pred))
```
*0.8468151*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_70,testresult)[4]))/((table(pred_70,testresult)[4])+(table(pred_70,testresult)[3]))
```
*0.2045818*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_70,testresult)[4]))/((table(pred_70,testresult)[4])+(table(pred_70,testresult)[2]))
```
*0.0157959*


Si cogemos que la probabilidad de corte para que sea clasificación=1 (tiene daño corporal) que la probabilidad sea > que 0.9:
```{r}
pred_90 <- as.factor(ifelse(pred$`1`>0.9,"1","0"))
table(pred_90,testresult)
```

|  |0     | 1    |
|--|-------|-------|
|0|2046476|23315 |
|1|32905 |475  |


Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_90,testresult)[4])+(table(pred_90,testresult)[1]))/(nrow(pred))
```
*0.9732689*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_90,testresult)[4]))/((table(pred_90,testresult)[4])+(table(pred_90,testresult)[3]))
```
*0.01996637*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_90,testresult)[4]))/((table(pred_90,testresult)[4])+(table(pred_90,testresult)[2]))
```
*0.01423008*

Si cogemos que la probabilidad de corte para que sea clasificación=1 (tiene daño corporal) que la probabilidad sea > que 0.95:
```{r}
pred_95 <- as.factor(ifelse(pred$`1`>0.95,"1","0"))
table(pred_95,testresult)
```

|  |0     | 1    |
|--|-------|-------|
|0|2051729|23419 |
|1|27652 |371  |


Accuracy:
True Positive+ True Negative / Total Observations
```{r}
((table(pred_95,testresult)[4])+(table(pred_95,testresult)[1]))/(nrow(pred))
```
*0.9757171*

Precisión:
True Positives / (True Positives + False Positives).
```{r}
((table(pred_95,testresult)[4]))/((table(pred_95,testresult)[4])+(table(pred_95,testresult)[3]))
```
*0.01559479*

Recall:
True Positives / (True Positives + False Negatives).
```{r}
((table(pred_95,testresult)[4]))/((table(pred_95,testresult)[4])+(table(pred_95,testresult)[2]))
```
*0.01323913*


